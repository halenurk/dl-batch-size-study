{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tf-cpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "55000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "print(mnist.train.num_examples) # Number of training data\n",
    "print(mnist.test.num_examples) # Number of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "learningrate = 0.002\n",
    "num_of_epochs=50\n",
    "batchsize = 128\n",
    "num_of_iters=55000/batchsize*num_of_epochs\n",
    "\n",
    "\n",
    "noutput = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, noutput])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # reshape input to 28x28 size\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # Convolution layer 1\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    # Max pooling\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution layer 2\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    # Max pooling\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # Fully connected layer\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out\n",
    "\n",
    "init_var=tf.contrib.layers.variance_scaling_initializer()\n",
    "init_xavier=tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "weights = {\n",
    "    'wc1': tf.get_variable(\"wc1\", shape=[5, 5, 1, 32],initializer=init_var),\n",
    "    'wc2': tf.get_variable(\"wc2\", shape=[5, 5, 32, 64],initializer=init_var),\n",
    "    'wd1': tf.get_variable(\"wd1\", shape=[7*7*64, 1024],initializer=init_var),\n",
    "    'out': tf.get_variable(\"out\", shape=[1024,noutput],initializer=init_var)\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.zeros([32])),\n",
    "    'bc2': tf.Variable(tf.zeros([64])),\n",
    "    'bd1': tf.Variable(tf.zeros([1024])),\n",
    "    'out': tf.Variable(tf.zeros([noutput]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = conv_net(X, weights, biases, dropout=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = model, labels=Y))\n",
    "#optimizer = tf.train.AdamOptimizer(learning_rate=learningrate)\n",
    "#optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "optimizer=tf.train.MomentumOptimizer(learning_rate=learningrate, momentum=0.99)\n",
    "\n",
    "train_min = optimizer.minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "tf.summary.scalar(\"trainingLoss\", loss)\n",
    "merged_summary_op = tf.summary.merge_all()\n",
    "filename = \"./log/mnist_project_batchsize128_lr0p002\" \n",
    "writer = tf.summary.FileWriter(filename, tf.get_default_graph())\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1, Training Loss: 2.5624, Training Accuracy: 0.1094\n",
      "Iteration: 11, Training Loss: 1.6846, Training Accuracy: 0.5000\n",
      "Iteration: 21, Training Loss: 1.1829, Training Accuracy: 0.6484\n",
      "Iteration: 31, Training Loss: 0.7664, Training Accuracy: 0.7578\n",
      "Iteration: 41, Training Loss: 0.7071, Training Accuracy: 0.7969\n",
      "Iteration: 51, Training Loss: 0.5944, Training Accuracy: 0.8047\n",
      "Iteration: 61, Training Loss: 0.4489, Training Accuracy: 0.8984\n",
      "Iteration: 71, Training Loss: 0.5697, Training Accuracy: 0.8516\n",
      "Iteration: 81, Training Loss: 0.2370, Training Accuracy: 0.9375\n",
      "Iteration: 91, Training Loss: 0.3530, Training Accuracy: 0.8828\n",
      "Iteration: 101, Training Loss: 0.4487, Training Accuracy: 0.8750\n",
      "Iteration: 111, Training Loss: 0.2382, Training Accuracy: 0.9141\n",
      "Iteration: 121, Training Loss: 0.2812, Training Accuracy: 0.9062\n",
      "Iteration: 131, Training Loss: 0.2764, Training Accuracy: 0.9375\n",
      "Iteration: 141, Training Loss: 0.2275, Training Accuracy: 0.8984\n",
      "Iteration: 151, Training Loss: 0.2923, Training Accuracy: 0.9062\n",
      "Iteration: 161, Training Loss: 0.1506, Training Accuracy: 0.9609\n",
      "Iteration: 171, Training Loss: 0.1680, Training Accuracy: 0.9453\n",
      "Iteration: 181, Training Loss: 0.0853, Training Accuracy: 0.9766\n",
      "Iteration: 191, Training Loss: 0.0964, Training Accuracy: 0.9844\n",
      "Iteration: 201, Training Loss: 0.2029, Training Accuracy: 0.9609\n",
      "Iteration: 211, Training Loss: 0.1062, Training Accuracy: 0.9531\n",
      "Iteration: 221, Training Loss: 0.1858, Training Accuracy: 0.9453\n",
      "Iteration: 231, Training Loss: 0.0984, Training Accuracy: 0.9688\n",
      "Iteration: 241, Training Loss: 0.1969, Training Accuracy: 0.9453\n",
      "Iteration: 251, Training Loss: 0.0972, Training Accuracy: 0.9688\n",
      "Iteration: 261, Training Loss: 0.0753, Training Accuracy: 0.9609\n",
      "Iteration: 271, Training Loss: 0.0710, Training Accuracy: 0.9844\n",
      "Iteration: 281, Training Loss: 0.0604, Training Accuracy: 0.9766\n",
      "Iteration: 291, Training Loss: 0.0940, Training Accuracy: 0.9688\n",
      "Iteration: 301, Training Loss: 0.0901, Training Accuracy: 0.9766\n",
      "Iteration: 311, Training Loss: 0.0500, Training Accuracy: 0.9688\n",
      "Iteration: 321, Training Loss: 0.0717, Training Accuracy: 0.9844\n",
      "Iteration: 331, Training Loss: 0.1149, Training Accuracy: 0.9609\n",
      "Iteration: 341, Training Loss: 0.0762, Training Accuracy: 0.9688\n",
      "Iteration: 351, Training Loss: 0.0510, Training Accuracy: 0.9766\n",
      "Iteration: 361, Training Loss: 0.0896, Training Accuracy: 0.9766\n",
      "Iteration: 371, Training Loss: 0.0692, Training Accuracy: 0.9688\n",
      "Iteration: 381, Training Loss: 0.1186, Training Accuracy: 0.9766\n",
      "Iteration: 391, Training Loss: 0.1057, Training Accuracy: 0.9609\n",
      "Iteration: 401, Training Loss: 0.0542, Training Accuracy: 0.9766\n",
      "Iteration: 411, Training Loss: 0.0713, Training Accuracy: 0.9922\n",
      "Iteration: 421, Training Loss: 0.0922, Training Accuracy: 0.9766\n",
      "Iteration: 431, Training Loss: 0.0641, Training Accuracy: 0.9844\n",
      "Iteration: 441, Training Loss: 0.0831, Training Accuracy: 0.9844\n",
      "Iteration: 451, Training Loss: 0.0457, Training Accuracy: 0.9766\n",
      "Iteration: 461, Training Loss: 0.0675, Training Accuracy: 0.9844\n",
      "Iteration: 471, Training Loss: 0.0706, Training Accuracy: 0.9688\n",
      "Iteration: 481, Training Loss: 0.0519, Training Accuracy: 0.9844\n",
      "Iteration: 491, Training Loss: 0.0428, Training Accuracy: 0.9844\n",
      "Iteration: 501, Training Loss: 0.0284, Training Accuracy: 1.0000\n",
      "Iteration: 511, Training Loss: 0.0754, Training Accuracy: 0.9844\n",
      "Iteration: 521, Training Loss: 0.0638, Training Accuracy: 0.9766\n",
      "Iteration: 531, Training Loss: 0.0821, Training Accuracy: 0.9688\n",
      "Iteration: 541, Training Loss: 0.0426, Training Accuracy: 0.9844\n",
      "Iteration: 551, Training Loss: 0.0281, Training Accuracy: 0.9922\n",
      "Iteration: 561, Training Loss: 0.0318, Training Accuracy: 0.9922\n",
      "Iteration: 571, Training Loss: 0.0343, Training Accuracy: 0.9922\n",
      "Iteration: 581, Training Loss: 0.0605, Training Accuracy: 0.9844\n",
      "Iteration: 591, Training Loss: 0.0370, Training Accuracy: 0.9922\n",
      "Iteration: 601, Training Loss: 0.0599, Training Accuracy: 0.9844\n",
      "Iteration: 611, Training Loss: 0.0681, Training Accuracy: 0.9766\n",
      "Iteration: 621, Training Loss: 0.0286, Training Accuracy: 0.9922\n",
      "Iteration: 631, Training Loss: 0.0500, Training Accuracy: 0.9844\n",
      "Iteration: 641, Training Loss: 0.1168, Training Accuracy: 0.9688\n",
      "Iteration: 651, Training Loss: 0.0628, Training Accuracy: 0.9688\n",
      "Iteration: 661, Training Loss: 0.0266, Training Accuracy: 1.0000\n",
      "Iteration: 671, Training Loss: 0.0853, Training Accuracy: 0.9766\n",
      "Iteration: 681, Training Loss: 0.0380, Training Accuracy: 0.9844\n",
      "Iteration: 691, Training Loss: 0.0544, Training Accuracy: 0.9922\n",
      "Iteration: 701, Training Loss: 0.0823, Training Accuracy: 0.9766\n",
      "Iteration: 711, Training Loss: 0.0500, Training Accuracy: 0.9922\n",
      "Iteration: 721, Training Loss: 0.0300, Training Accuracy: 0.9922\n",
      "Iteration: 731, Training Loss: 0.1028, Training Accuracy: 0.9688\n",
      "Iteration: 741, Training Loss: 0.0502, Training Accuracy: 0.9766\n",
      "Iteration: 751, Training Loss: 0.0254, Training Accuracy: 1.0000\n",
      "Iteration: 761, Training Loss: 0.0082, Training Accuracy: 1.0000\n",
      "Iteration: 771, Training Loss: 0.0589, Training Accuracy: 0.9609\n",
      "Iteration: 781, Training Loss: 0.1161, Training Accuracy: 0.9844\n",
      "Iteration: 791, Training Loss: 0.0635, Training Accuracy: 0.9766\n",
      "Iteration: 801, Training Loss: 0.0839, Training Accuracy: 0.9844\n",
      "Iteration: 811, Training Loss: 0.0268, Training Accuracy: 0.9922\n",
      "Iteration: 821, Training Loss: 0.1135, Training Accuracy: 0.9688\n",
      "Iteration: 831, Training Loss: 0.0372, Training Accuracy: 0.9844\n",
      "Iteration: 841, Training Loss: 0.0190, Training Accuracy: 0.9922\n",
      "Iteration: 851, Training Loss: 0.1020, Training Accuracy: 0.9531\n",
      "Iteration: 861, Training Loss: 0.0304, Training Accuracy: 1.0000\n",
      "Iteration: 871, Training Loss: 0.0722, Training Accuracy: 0.9766\n",
      "Iteration: 881, Training Loss: 0.0323, Training Accuracy: 0.9844\n",
      "Iteration: 891, Training Loss: 0.0483, Training Accuracy: 0.9922\n",
      "Iteration: 901, Training Loss: 0.0550, Training Accuracy: 0.9844\n",
      "Iteration: 911, Training Loss: 0.0194, Training Accuracy: 0.9922\n",
      "Iteration: 921, Training Loss: 0.0292, Training Accuracy: 0.9922\n",
      "Iteration: 931, Training Loss: 0.0189, Training Accuracy: 0.9922\n",
      "Iteration: 941, Training Loss: 0.0297, Training Accuracy: 0.9922\n",
      "Iteration: 951, Training Loss: 0.0281, Training Accuracy: 0.9922\n",
      "Iteration: 961, Training Loss: 0.0268, Training Accuracy: 0.9922\n",
      "Iteration: 971, Training Loss: 0.0194, Training Accuracy: 1.0000\n",
      "Iteration: 981, Training Loss: 0.0149, Training Accuracy: 1.0000\n",
      "Iteration: 991, Training Loss: 0.0393, Training Accuracy: 0.9844\n",
      "Iteration: 1001, Training Loss: 0.0941, Training Accuracy: 0.9844\n",
      "Iteration: 1011, Training Loss: 0.0217, Training Accuracy: 0.9844\n",
      "Iteration: 1021, Training Loss: 0.0373, Training Accuracy: 0.9922\n",
      "Iteration: 1031, Training Loss: 0.0665, Training Accuracy: 0.9766\n",
      "Iteration: 1041, Training Loss: 0.0286, Training Accuracy: 0.9766\n",
      "Iteration: 1051, Training Loss: 0.0110, Training Accuracy: 1.0000\n",
      "Iteration: 1061, Training Loss: 0.0314, Training Accuracy: 0.9922\n",
      "Iteration: 1071, Training Loss: 0.0509, Training Accuracy: 0.9844\n",
      "Iteration: 1081, Training Loss: 0.0216, Training Accuracy: 0.9922\n",
      "Iteration: 1091, Training Loss: 0.0125, Training Accuracy: 1.0000\n",
      "Iteration: 1101, Training Loss: 0.0089, Training Accuracy: 1.0000\n",
      "Iteration: 1111, Training Loss: 0.0165, Training Accuracy: 1.0000\n",
      "Iteration: 1121, Training Loss: 0.0108, Training Accuracy: 0.9922\n",
      "Iteration: 1131, Training Loss: 0.0693, Training Accuracy: 0.9688\n",
      "Iteration: 1141, Training Loss: 0.0100, Training Accuracy: 1.0000\n",
      "Iteration: 1151, Training Loss: 0.0134, Training Accuracy: 1.0000\n",
      "Iteration: 1161, Training Loss: 0.1048, Training Accuracy: 0.9766\n",
      "Iteration: 1171, Training Loss: 0.0565, Training Accuracy: 0.9844\n",
      "Iteration: 1181, Training Loss: 0.0551, Training Accuracy: 0.9922\n",
      "Iteration: 1191, Training Loss: 0.0580, Training Accuracy: 0.9844\n",
      "Iteration: 1201, Training Loss: 0.0782, Training Accuracy: 0.9766\n",
      "Iteration: 1211, Training Loss: 0.0163, Training Accuracy: 0.9922\n",
      "Iteration: 1221, Training Loss: 0.0456, Training Accuracy: 0.9766\n",
      "Iteration: 1231, Training Loss: 0.0149, Training Accuracy: 1.0000\n",
      "Iteration: 1241, Training Loss: 0.0462, Training Accuracy: 0.9922\n",
      "Iteration: 1251, Training Loss: 0.0266, Training Accuracy: 0.9922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1261, Training Loss: 0.0166, Training Accuracy: 0.9922\n",
      "Iteration: 1271, Training Loss: 0.0150, Training Accuracy: 0.9922\n",
      "Iteration: 1281, Training Loss: 0.0140, Training Accuracy: 1.0000\n",
      "Iteration: 1291, Training Loss: 0.0528, Training Accuracy: 0.9766\n",
      "Iteration: 1301, Training Loss: 0.0549, Training Accuracy: 0.9844\n",
      "Iteration: 1311, Training Loss: 0.0785, Training Accuracy: 0.9766\n",
      "Iteration: 1321, Training Loss: 0.0355, Training Accuracy: 0.9922\n",
      "Iteration: 1331, Training Loss: 0.0887, Training Accuracy: 0.9766\n",
      "Iteration: 1341, Training Loss: 0.0094, Training Accuracy: 1.0000\n",
      "Iteration: 1351, Training Loss: 0.0231, Training Accuracy: 0.9922\n",
      "Iteration: 1361, Training Loss: 0.0089, Training Accuracy: 1.0000\n",
      "Iteration: 1371, Training Loss: 0.1072, Training Accuracy: 0.9766\n",
      "Iteration: 1381, Training Loss: 0.0057, Training Accuracy: 1.0000\n",
      "Iteration: 1391, Training Loss: 0.0043, Training Accuracy: 1.0000\n",
      "Iteration: 1401, Training Loss: 0.0361, Training Accuracy: 0.9922\n",
      "Iteration: 1411, Training Loss: 0.0185, Training Accuracy: 0.9844\n",
      "Iteration: 1421, Training Loss: 0.0317, Training Accuracy: 0.9922\n",
      "Iteration: 1431, Training Loss: 0.0395, Training Accuracy: 0.9922\n",
      "Iteration: 1441, Training Loss: 0.0142, Training Accuracy: 1.0000\n",
      "Iteration: 1451, Training Loss: 0.0038, Training Accuracy: 1.0000\n",
      "Iteration: 1461, Training Loss: 0.0165, Training Accuracy: 0.9922\n",
      "Iteration: 1471, Training Loss: 0.0075, Training Accuracy: 1.0000\n",
      "Iteration: 1481, Training Loss: 0.0456, Training Accuracy: 0.9844\n",
      "Iteration: 1491, Training Loss: 0.0278, Training Accuracy: 0.9922\n",
      "Iteration: 1501, Training Loss: 0.0472, Training Accuracy: 0.9766\n",
      "Iteration: 1511, Training Loss: 0.0675, Training Accuracy: 0.9844\n",
      "Iteration: 1521, Training Loss: 0.0098, Training Accuracy: 1.0000\n",
      "Iteration: 1531, Training Loss: 0.0083, Training Accuracy: 1.0000\n",
      "Iteration: 1541, Training Loss: 0.0561, Training Accuracy: 0.9766\n",
      "Iteration: 1551, Training Loss: 0.0125, Training Accuracy: 1.0000\n",
      "Iteration: 1561, Training Loss: 0.0171, Training Accuracy: 1.0000\n",
      "Iteration: 1571, Training Loss: 0.0884, Training Accuracy: 0.9844\n",
      "Iteration: 1581, Training Loss: 0.0111, Training Accuracy: 1.0000\n",
      "Iteration: 1591, Training Loss: 0.0108, Training Accuracy: 1.0000\n",
      "Iteration: 1601, Training Loss: 0.0184, Training Accuracy: 0.9922\n",
      "Iteration: 1611, Training Loss: 0.0150, Training Accuracy: 0.9922\n",
      "Iteration: 1621, Training Loss: 0.0169, Training Accuracy: 1.0000\n",
      "Iteration: 1631, Training Loss: 0.0120, Training Accuracy: 1.0000\n",
      "Iteration: 1641, Training Loss: 0.1167, Training Accuracy: 0.9531\n",
      "Iteration: 1651, Training Loss: 0.0082, Training Accuracy: 1.0000\n",
      "Iteration: 1661, Training Loss: 0.0645, Training Accuracy: 0.9922\n",
      "Iteration: 1671, Training Loss: 0.0533, Training Accuracy: 0.9688\n",
      "Iteration: 1681, Training Loss: 0.0388, Training Accuracy: 0.9844\n",
      "Iteration: 1691, Training Loss: 0.0276, Training Accuracy: 0.9844\n",
      "Iteration: 1701, Training Loss: 0.0205, Training Accuracy: 0.9844\n",
      "Iteration: 1711, Training Loss: 0.0062, Training Accuracy: 1.0000\n",
      "Iteration: 1721, Training Loss: 0.0251, Training Accuracy: 1.0000\n",
      "Iteration: 1731, Training Loss: 0.0307, Training Accuracy: 0.9844\n",
      "Iteration: 1741, Training Loss: 0.0849, Training Accuracy: 0.9844\n",
      "Iteration: 1751, Training Loss: 0.0196, Training Accuracy: 0.9844\n",
      "Iteration: 1761, Training Loss: 0.0333, Training Accuracy: 0.9844\n",
      "Iteration: 1771, Training Loss: 0.0154, Training Accuracy: 1.0000\n",
      "Iteration: 1781, Training Loss: 0.0311, Training Accuracy: 0.9844\n",
      "Iteration: 1791, Training Loss: 0.0073, Training Accuracy: 1.0000\n",
      "Iteration: 1801, Training Loss: 0.0182, Training Accuracy: 0.9922\n",
      "Iteration: 1811, Training Loss: 0.0481, Training Accuracy: 0.9844\n",
      "Iteration: 1821, Training Loss: 0.0148, Training Accuracy: 0.9922\n",
      "Iteration: 1831, Training Loss: 0.0097, Training Accuracy: 0.9922\n",
      "Iteration: 1841, Training Loss: 0.0331, Training Accuracy: 0.9766\n",
      "Iteration: 1851, Training Loss: 0.0132, Training Accuracy: 0.9922\n",
      "Iteration: 1861, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 1871, Training Loss: 0.0153, Training Accuracy: 1.0000\n",
      "Iteration: 1881, Training Loss: 0.0454, Training Accuracy: 0.9844\n",
      "Iteration: 1891, Training Loss: 0.0060, Training Accuracy: 1.0000\n",
      "Iteration: 1901, Training Loss: 0.0140, Training Accuracy: 0.9922\n",
      "Iteration: 1911, Training Loss: 0.0118, Training Accuracy: 0.9922\n",
      "Iteration: 1921, Training Loss: 0.0239, Training Accuracy: 0.9922\n",
      "Iteration: 1931, Training Loss: 0.0478, Training Accuracy: 0.9688\n",
      "Iteration: 1941, Training Loss: 0.0042, Training Accuracy: 1.0000\n",
      "Iteration: 1951, Training Loss: 0.0019, Training Accuracy: 1.0000\n",
      "Iteration: 1961, Training Loss: 0.0367, Training Accuracy: 0.9922\n",
      "Iteration: 1971, Training Loss: 0.0153, Training Accuracy: 1.0000\n",
      "Iteration: 1981, Training Loss: 0.0219, Training Accuracy: 0.9844\n",
      "Iteration: 1991, Training Loss: 0.0052, Training Accuracy: 1.0000\n",
      "Iteration: 2001, Training Loss: 0.0074, Training Accuracy: 1.0000\n",
      "Iteration: 2011, Training Loss: 0.0163, Training Accuracy: 1.0000\n",
      "Iteration: 2021, Training Loss: 0.0203, Training Accuracy: 0.9922\n",
      "Iteration: 2031, Training Loss: 0.0152, Training Accuracy: 1.0000\n",
      "Iteration: 2041, Training Loss: 0.0108, Training Accuracy: 1.0000\n",
      "Iteration: 2051, Training Loss: 0.0150, Training Accuracy: 0.9922\n",
      "Iteration: 2061, Training Loss: 0.0439, Training Accuracy: 0.9844\n",
      "Iteration: 2071, Training Loss: 0.0195, Training Accuracy: 0.9922\n",
      "Iteration: 2081, Training Loss: 0.0089, Training Accuracy: 1.0000\n",
      "Iteration: 2091, Training Loss: 0.0271, Training Accuracy: 0.9844\n",
      "Iteration: 2101, Training Loss: 0.0324, Training Accuracy: 0.9844\n",
      "Iteration: 2111, Training Loss: 0.0232, Training Accuracy: 0.9922\n",
      "Iteration: 2121, Training Loss: 0.0059, Training Accuracy: 1.0000\n",
      "Iteration: 2131, Training Loss: 0.0070, Training Accuracy: 1.0000\n",
      "Iteration: 2141, Training Loss: 0.0177, Training Accuracy: 0.9922\n",
      "Iteration: 2151, Training Loss: 0.0148, Training Accuracy: 0.9922\n",
      "Iteration: 2161, Training Loss: 0.0062, Training Accuracy: 1.0000\n",
      "Iteration: 2171, Training Loss: 0.0211, Training Accuracy: 0.9922\n",
      "Iteration: 2181, Training Loss: 0.0159, Training Accuracy: 0.9922\n",
      "Iteration: 2191, Training Loss: 0.0077, Training Accuracy: 1.0000\n",
      "Iteration: 2201, Training Loss: 0.0048, Training Accuracy: 1.0000\n",
      "Iteration: 2211, Training Loss: 0.0277, Training Accuracy: 0.9844\n",
      "Iteration: 2221, Training Loss: 0.0087, Training Accuracy: 1.0000\n",
      "Iteration: 2231, Training Loss: 0.0127, Training Accuracy: 0.9922\n",
      "Iteration: 2241, Training Loss: 0.0092, Training Accuracy: 1.0000\n",
      "Iteration: 2251, Training Loss: 0.0229, Training Accuracy: 0.9922\n",
      "Iteration: 2261, Training Loss: 0.0070, Training Accuracy: 1.0000\n",
      "Iteration: 2271, Training Loss: 0.0622, Training Accuracy: 0.9688\n",
      "Iteration: 2281, Training Loss: 0.0167, Training Accuracy: 0.9922\n",
      "Iteration: 2291, Training Loss: 0.0234, Training Accuracy: 0.9922\n",
      "Iteration: 2301, Training Loss: 0.0275, Training Accuracy: 0.9922\n",
      "Iteration: 2311, Training Loss: 0.0439, Training Accuracy: 0.9922\n",
      "Iteration: 2321, Training Loss: 0.0016, Training Accuracy: 1.0000\n",
      "Iteration: 2331, Training Loss: 0.0049, Training Accuracy: 1.0000\n",
      "Iteration: 2341, Training Loss: 0.0955, Training Accuracy: 0.9609\n",
      "Iteration: 2351, Training Loss: 0.0128, Training Accuracy: 1.0000\n",
      "Iteration: 2361, Training Loss: 0.0243, Training Accuracy: 0.9844\n",
      "Iteration: 2371, Training Loss: 0.0039, Training Accuracy: 1.0000\n",
      "Iteration: 2381, Training Loss: 0.0156, Training Accuracy: 0.9922\n",
      "Iteration: 2391, Training Loss: 0.0102, Training Accuracy: 1.0000\n",
      "Iteration: 2401, Training Loss: 0.0421, Training Accuracy: 0.9766\n",
      "Iteration: 2411, Training Loss: 0.0042, Training Accuracy: 1.0000\n",
      "Iteration: 2421, Training Loss: 0.0279, Training Accuracy: 0.9922\n",
      "Iteration: 2431, Training Loss: 0.0036, Training Accuracy: 1.0000\n",
      "Iteration: 2441, Training Loss: 0.0195, Training Accuracy: 0.9922\n",
      "Iteration: 2451, Training Loss: 0.0142, Training Accuracy: 0.9922\n",
      "Iteration: 2461, Training Loss: 0.0666, Training Accuracy: 0.9688\n",
      "Iteration: 2471, Training Loss: 0.0134, Training Accuracy: 1.0000\n",
      "Iteration: 2481, Training Loss: 0.0254, Training Accuracy: 0.9922\n",
      "Iteration: 2491, Training Loss: 0.0203, Training Accuracy: 0.9922\n",
      "Iteration: 2501, Training Loss: 0.0111, Training Accuracy: 0.9922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2511, Training Loss: 0.0025, Training Accuracy: 1.0000\n",
      "Iteration: 2521, Training Loss: 0.0345, Training Accuracy: 0.9766\n",
      "Iteration: 2531, Training Loss: 0.0509, Training Accuracy: 0.9844\n",
      "Iteration: 2541, Training Loss: 0.0483, Training Accuracy: 0.9922\n",
      "Iteration: 2551, Training Loss: 0.0063, Training Accuracy: 1.0000\n",
      "Iteration: 2561, Training Loss: 0.0052, Training Accuracy: 1.0000\n",
      "Iteration: 2571, Training Loss: 0.0162, Training Accuracy: 0.9922\n",
      "Iteration: 2581, Training Loss: 0.0389, Training Accuracy: 0.9844\n",
      "Iteration: 2591, Training Loss: 0.0026, Training Accuracy: 1.0000\n",
      "Iteration: 2601, Training Loss: 0.0031, Training Accuracy: 1.0000\n",
      "Iteration: 2611, Training Loss: 0.0025, Training Accuracy: 1.0000\n",
      "Iteration: 2621, Training Loss: 0.0080, Training Accuracy: 1.0000\n",
      "Iteration: 2631, Training Loss: 0.0196, Training Accuracy: 0.9922\n",
      "Iteration: 2641, Training Loss: 0.0062, Training Accuracy: 1.0000\n",
      "Iteration: 2651, Training Loss: 0.0104, Training Accuracy: 1.0000\n",
      "Iteration: 2661, Training Loss: 0.0059, Training Accuracy: 1.0000\n",
      "Iteration: 2671, Training Loss: 0.0023, Training Accuracy: 1.0000\n",
      "Iteration: 2681, Training Loss: 0.0088, Training Accuracy: 0.9922\n",
      "Iteration: 2691, Training Loss: 0.0271, Training Accuracy: 0.9922\n",
      "Iteration: 2701, Training Loss: 0.0081, Training Accuracy: 1.0000\n",
      "Iteration: 2711, Training Loss: 0.0048, Training Accuracy: 1.0000\n",
      "Iteration: 2721, Training Loss: 0.0054, Training Accuracy: 1.0000\n",
      "Iteration: 2731, Training Loss: 0.0192, Training Accuracy: 0.9922\n",
      "Iteration: 2741, Training Loss: 0.0052, Training Accuracy: 1.0000\n",
      "Iteration: 2751, Training Loss: 0.0214, Training Accuracy: 0.9922\n",
      "Iteration: 2761, Training Loss: 0.0048, Training Accuracy: 1.0000\n",
      "Iteration: 2771, Training Loss: 0.0041, Training Accuracy: 1.0000\n",
      "Iteration: 2781, Training Loss: 0.0148, Training Accuracy: 0.9922\n",
      "Iteration: 2791, Training Loss: 0.0044, Training Accuracy: 1.0000\n",
      "Iteration: 2801, Training Loss: 0.0244, Training Accuracy: 0.9922\n",
      "Iteration: 2811, Training Loss: 0.0150, Training Accuracy: 0.9922\n",
      "Iteration: 2821, Training Loss: 0.0114, Training Accuracy: 1.0000\n",
      "Iteration: 2831, Training Loss: 0.0020, Training Accuracy: 1.0000\n",
      "Iteration: 2841, Training Loss: 0.0056, Training Accuracy: 1.0000\n",
      "Iteration: 2851, Training Loss: 0.0038, Training Accuracy: 1.0000\n",
      "Iteration: 2861, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 2871, Training Loss: 0.0042, Training Accuracy: 1.0000\n",
      "Iteration: 2881, Training Loss: 0.0418, Training Accuracy: 0.9922\n",
      "Iteration: 2891, Training Loss: 0.0068, Training Accuracy: 1.0000\n",
      "Iteration: 2901, Training Loss: 0.0263, Training Accuracy: 0.9922\n",
      "Iteration: 2911, Training Loss: 0.0237, Training Accuracy: 0.9844\n",
      "Iteration: 2921, Training Loss: 0.0560, Training Accuracy: 0.9844\n",
      "Iteration: 2931, Training Loss: 0.0021, Training Accuracy: 1.0000\n",
      "Iteration: 2941, Training Loss: 0.0031, Training Accuracy: 1.0000\n",
      "Iteration: 2951, Training Loss: 0.0144, Training Accuracy: 0.9922\n",
      "Iteration: 2961, Training Loss: 0.0436, Training Accuracy: 0.9844\n",
      "Iteration: 2971, Training Loss: 0.0094, Training Accuracy: 1.0000\n",
      "Iteration: 2981, Training Loss: 0.0331, Training Accuracy: 0.9922\n",
      "Iteration: 2991, Training Loss: 0.0038, Training Accuracy: 1.0000\n",
      "Iteration: 3001, Training Loss: 0.0023, Training Accuracy: 1.0000\n",
      "Iteration: 3011, Training Loss: 0.0222, Training Accuracy: 0.9922\n",
      "Iteration: 3021, Training Loss: 0.0501, Training Accuracy: 0.9844\n",
      "Iteration: 3031, Training Loss: 0.0468, Training Accuracy: 0.9844\n",
      "Iteration: 3041, Training Loss: 0.0195, Training Accuracy: 0.9922\n",
      "Iteration: 3051, Training Loss: 0.0290, Training Accuracy: 0.9844\n",
      "Iteration: 3061, Training Loss: 0.0114, Training Accuracy: 0.9922\n",
      "Iteration: 3071, Training Loss: 0.0164, Training Accuracy: 0.9922\n",
      "Iteration: 3081, Training Loss: 0.0229, Training Accuracy: 0.9922\n",
      "Iteration: 3091, Training Loss: 0.0137, Training Accuracy: 0.9922\n",
      "Iteration: 3101, Training Loss: 0.0087, Training Accuracy: 0.9922\n",
      "Iteration: 3111, Training Loss: 0.0231, Training Accuracy: 0.9922\n",
      "Iteration: 3121, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 3131, Training Loss: 0.0054, Training Accuracy: 1.0000\n",
      "Iteration: 3141, Training Loss: 0.0184, Training Accuracy: 0.9922\n",
      "Iteration: 3151, Training Loss: 0.0271, Training Accuracy: 0.9922\n",
      "Iteration: 3161, Training Loss: 0.0163, Training Accuracy: 0.9922\n",
      "Iteration: 3171, Training Loss: 0.0246, Training Accuracy: 0.9922\n",
      "Iteration: 3181, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 3191, Training Loss: 0.0037, Training Accuracy: 1.0000\n",
      "Iteration: 3201, Training Loss: 0.0103, Training Accuracy: 1.0000\n",
      "Iteration: 3211, Training Loss: 0.0155, Training Accuracy: 0.9922\n",
      "Iteration: 3221, Training Loss: 0.0032, Training Accuracy: 1.0000\n",
      "Iteration: 3231, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 3241, Training Loss: 0.0131, Training Accuracy: 0.9922\n",
      "Iteration: 3251, Training Loss: 0.0111, Training Accuracy: 0.9922\n",
      "Iteration: 3261, Training Loss: 0.0027, Training Accuracy: 1.0000\n",
      "Iteration: 3271, Training Loss: 0.0408, Training Accuracy: 0.9844\n",
      "Iteration: 3281, Training Loss: 0.0325, Training Accuracy: 0.9844\n",
      "Iteration: 3291, Training Loss: 0.0030, Training Accuracy: 1.0000\n",
      "Iteration: 3301, Training Loss: 0.0122, Training Accuracy: 0.9922\n",
      "Iteration: 3311, Training Loss: 0.0028, Training Accuracy: 1.0000\n",
      "Iteration: 3321, Training Loss: 0.0134, Training Accuracy: 0.9922\n",
      "Iteration: 3331, Training Loss: 0.0023, Training Accuracy: 1.0000\n",
      "Iteration: 3341, Training Loss: 0.0190, Training Accuracy: 0.9922\n",
      "Iteration: 3351, Training Loss: 0.0211, Training Accuracy: 0.9922\n",
      "Iteration: 3361, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 3371, Training Loss: 0.0224, Training Accuracy: 0.9922\n",
      "Iteration: 3381, Training Loss: 0.0349, Training Accuracy: 0.9844\n",
      "Iteration: 3391, Training Loss: 0.0140, Training Accuracy: 0.9922\n",
      "Iteration: 3401, Training Loss: 0.2001, Training Accuracy: 0.9844\n",
      "Iteration: 3411, Training Loss: 0.0258, Training Accuracy: 0.9922\n",
      "Iteration: 3421, Training Loss: 0.0087, Training Accuracy: 0.9922\n",
      "Iteration: 3431, Training Loss: 0.0054, Training Accuracy: 1.0000\n",
      "Iteration: 3441, Training Loss: 0.0338, Training Accuracy: 0.9844\n",
      "Iteration: 3451, Training Loss: 0.0062, Training Accuracy: 1.0000\n",
      "Iteration: 3461, Training Loss: 0.0047, Training Accuracy: 1.0000\n",
      "Iteration: 3471, Training Loss: 0.0200, Training Accuracy: 1.0000\n",
      "Iteration: 3481, Training Loss: 0.0035, Training Accuracy: 1.0000\n",
      "Iteration: 3491, Training Loss: 0.0210, Training Accuracy: 0.9922\n",
      "Iteration: 3501, Training Loss: 0.0169, Training Accuracy: 0.9844\n",
      "Iteration: 3511, Training Loss: 0.0286, Training Accuracy: 0.9844\n",
      "Iteration: 3521, Training Loss: 0.0136, Training Accuracy: 0.9922\n",
      "Iteration: 3531, Training Loss: 0.0120, Training Accuracy: 0.9922\n",
      "Iteration: 3541, Training Loss: 0.0316, Training Accuracy: 0.9844\n",
      "Iteration: 3551, Training Loss: 0.0058, Training Accuracy: 1.0000\n",
      "Iteration: 3561, Training Loss: 0.0275, Training Accuracy: 0.9844\n",
      "Iteration: 3571, Training Loss: 0.0019, Training Accuracy: 1.0000\n",
      "Iteration: 3581, Training Loss: 0.0339, Training Accuracy: 0.9922\n",
      "Iteration: 3591, Training Loss: 0.0149, Training Accuracy: 0.9922\n",
      "Iteration: 3601, Training Loss: 0.0284, Training Accuracy: 0.9922\n",
      "Iteration: 3611, Training Loss: 0.0046, Training Accuracy: 1.0000\n",
      "Iteration: 3621, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 3631, Training Loss: 0.0085, Training Accuracy: 1.0000\n",
      "Iteration: 3641, Training Loss: 0.0040, Training Accuracy: 1.0000\n",
      "Iteration: 3651, Training Loss: 0.0022, Training Accuracy: 1.0000\n",
      "Iteration: 3661, Training Loss: 0.0144, Training Accuracy: 0.9922\n",
      "Iteration: 3671, Training Loss: 0.0070, Training Accuracy: 1.0000\n",
      "Iteration: 3681, Training Loss: 0.0025, Training Accuracy: 1.0000\n",
      "Iteration: 3691, Training Loss: 0.0086, Training Accuracy: 1.0000\n",
      "Iteration: 3701, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 3711, Training Loss: 0.0066, Training Accuracy: 1.0000\n",
      "Iteration: 3721, Training Loss: 0.0060, Training Accuracy: 1.0000\n",
      "Iteration: 3731, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 3741, Training Loss: 0.0288, Training Accuracy: 0.9922\n",
      "Iteration: 3751, Training Loss: 0.0019, Training Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3761, Training Loss: 0.0256, Training Accuracy: 0.9922\n",
      "Iteration: 3771, Training Loss: 0.0030, Training Accuracy: 1.0000\n",
      "Iteration: 3781, Training Loss: 0.0044, Training Accuracy: 1.0000\n",
      "Iteration: 3791, Training Loss: 0.0070, Training Accuracy: 1.0000\n",
      "Iteration: 3801, Training Loss: 0.0073, Training Accuracy: 0.9922\n",
      "Iteration: 3811, Training Loss: 0.0063, Training Accuracy: 1.0000\n",
      "Iteration: 3821, Training Loss: 0.0271, Training Accuracy: 0.9922\n",
      "Iteration: 3831, Training Loss: 0.0117, Training Accuracy: 1.0000\n",
      "Iteration: 3841, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 3851, Training Loss: 0.0459, Training Accuracy: 0.9844\n",
      "Iteration: 3861, Training Loss: 0.0030, Training Accuracy: 1.0000\n",
      "Iteration: 3871, Training Loss: 0.0225, Training Accuracy: 0.9844\n",
      "Iteration: 3881, Training Loss: 0.0082, Training Accuracy: 1.0000\n",
      "Iteration: 3891, Training Loss: 0.0203, Training Accuracy: 0.9922\n",
      "Iteration: 3901, Training Loss: 0.0148, Training Accuracy: 1.0000\n",
      "Iteration: 3911, Training Loss: 0.0269, Training Accuracy: 0.9922\n",
      "Iteration: 3921, Training Loss: 0.0110, Training Accuracy: 1.0000\n",
      "Iteration: 3931, Training Loss: 0.0044, Training Accuracy: 1.0000\n",
      "Iteration: 3941, Training Loss: 0.0222, Training Accuracy: 0.9844\n",
      "Iteration: 3951, Training Loss: 0.1113, Training Accuracy: 0.9844\n",
      "Iteration: 3961, Training Loss: 0.0049, Training Accuracy: 1.0000\n",
      "Iteration: 3971, Training Loss: 0.0119, Training Accuracy: 0.9922\n",
      "Iteration: 3981, Training Loss: 0.0180, Training Accuracy: 0.9922\n",
      "Iteration: 3991, Training Loss: 0.0081, Training Accuracy: 1.0000\n",
      "Iteration: 4001, Training Loss: 0.0031, Training Accuracy: 1.0000\n",
      "Iteration: 4011, Training Loss: 0.0231, Training Accuracy: 0.9844\n",
      "Iteration: 4021, Training Loss: 0.0518, Training Accuracy: 0.9844\n",
      "Iteration: 4031, Training Loss: 0.0062, Training Accuracy: 1.0000\n",
      "Iteration: 4041, Training Loss: 0.0052, Training Accuracy: 1.0000\n",
      "Iteration: 4051, Training Loss: 0.0040, Training Accuracy: 1.0000\n",
      "Iteration: 4061, Training Loss: 0.0133, Training Accuracy: 0.9922\n",
      "Iteration: 4071, Training Loss: 0.0034, Training Accuracy: 1.0000\n",
      "Iteration: 4081, Training Loss: 0.0110, Training Accuracy: 1.0000\n",
      "Iteration: 4091, Training Loss: 0.0051, Training Accuracy: 1.0000\n",
      "Iteration: 4101, Training Loss: 0.0072, Training Accuracy: 1.0000\n",
      "Iteration: 4111, Training Loss: 0.0055, Training Accuracy: 1.0000\n",
      "Iteration: 4121, Training Loss: 0.0018, Training Accuracy: 1.0000\n",
      "Iteration: 4131, Training Loss: 0.0089, Training Accuracy: 1.0000\n",
      "Iteration: 4141, Training Loss: 0.0396, Training Accuracy: 0.9922\n",
      "Iteration: 4151, Training Loss: 0.0048, Training Accuracy: 1.0000\n",
      "Iteration: 4161, Training Loss: 0.0103, Training Accuracy: 0.9922\n",
      "Iteration: 4171, Training Loss: 0.0293, Training Accuracy: 0.9922\n",
      "Iteration: 4181, Training Loss: 0.0019, Training Accuracy: 1.0000\n",
      "Iteration: 4191, Training Loss: 0.0027, Training Accuracy: 1.0000\n",
      "Iteration: 4201, Training Loss: 0.0089, Training Accuracy: 0.9922\n",
      "Iteration: 4211, Training Loss: 0.0033, Training Accuracy: 1.0000\n",
      "Iteration: 4221, Training Loss: 0.0047, Training Accuracy: 1.0000\n",
      "Iteration: 4231, Training Loss: 0.0503, Training Accuracy: 0.9922\n",
      "Iteration: 4241, Training Loss: 0.0132, Training Accuracy: 0.9922\n",
      "Iteration: 4251, Training Loss: 0.0151, Training Accuracy: 0.9922\n",
      "Iteration: 4261, Training Loss: 0.0075, Training Accuracy: 1.0000\n",
      "Iteration: 4271, Training Loss: 0.0038, Training Accuracy: 1.0000\n",
      "Iteration: 4281, Training Loss: 0.0116, Training Accuracy: 1.0000\n",
      "Iteration: 4291, Training Loss: 0.0023, Training Accuracy: 1.0000\n",
      "Iteration: 4301, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 4311, Training Loss: 0.0070, Training Accuracy: 1.0000\n",
      "Iteration: 4321, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 4331, Training Loss: 0.0059, Training Accuracy: 1.0000\n",
      "Iteration: 4341, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 4351, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 4361, Training Loss: 0.0155, Training Accuracy: 0.9922\n",
      "Iteration: 4371, Training Loss: 0.0026, Training Accuracy: 1.0000\n",
      "Iteration: 4381, Training Loss: 0.0036, Training Accuracy: 1.0000\n",
      "Iteration: 4391, Training Loss: 0.0042, Training Accuracy: 1.0000\n",
      "Iteration: 4401, Training Loss: 0.0018, Training Accuracy: 1.0000\n",
      "Iteration: 4411, Training Loss: 0.0111, Training Accuracy: 0.9922\n",
      "Iteration: 4421, Training Loss: 0.0123, Training Accuracy: 0.9922\n",
      "Iteration: 4431, Training Loss: 0.0021, Training Accuracy: 1.0000\n",
      "Iteration: 4441, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 4451, Training Loss: 0.0094, Training Accuracy: 1.0000\n",
      "Iteration: 4461, Training Loss: 0.0111, Training Accuracy: 1.0000\n",
      "Iteration: 4471, Training Loss: 0.0039, Training Accuracy: 1.0000\n",
      "Iteration: 4481, Training Loss: 0.0036, Training Accuracy: 1.0000\n",
      "Iteration: 4491, Training Loss: 0.0145, Training Accuracy: 0.9922\n",
      "Iteration: 4501, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 4511, Training Loss: 0.0018, Training Accuracy: 1.0000\n",
      "Iteration: 4521, Training Loss: 0.0445, Training Accuracy: 0.9922\n",
      "Iteration: 4531, Training Loss: 0.0135, Training Accuracy: 0.9922\n",
      "Iteration: 4541, Training Loss: 0.0023, Training Accuracy: 1.0000\n",
      "Iteration: 4551, Training Loss: 0.0096, Training Accuracy: 1.0000\n",
      "Iteration: 4561, Training Loss: 0.0195, Training Accuracy: 0.9922\n",
      "Iteration: 4571, Training Loss: 0.0057, Training Accuracy: 1.0000\n",
      "Iteration: 4581, Training Loss: 0.0302, Training Accuracy: 0.9844\n",
      "Iteration: 4591, Training Loss: 0.0126, Training Accuracy: 0.9922\n",
      "Iteration: 4601, Training Loss: 0.0031, Training Accuracy: 1.0000\n",
      "Iteration: 4611, Training Loss: 0.0043, Training Accuracy: 1.0000\n",
      "Iteration: 4621, Training Loss: 0.0190, Training Accuracy: 0.9922\n",
      "Iteration: 4631, Training Loss: 0.0103, Training Accuracy: 1.0000\n",
      "Iteration: 4641, Training Loss: 0.0380, Training Accuracy: 0.9844\n",
      "Iteration: 4651, Training Loss: 0.0051, Training Accuracy: 1.0000\n",
      "Iteration: 4661, Training Loss: 0.0052, Training Accuracy: 1.0000\n",
      "Iteration: 4671, Training Loss: 0.0085, Training Accuracy: 1.0000\n",
      "Iteration: 4681, Training Loss: 0.0052, Training Accuracy: 1.0000\n",
      "Iteration: 4691, Training Loss: 0.0019, Training Accuracy: 1.0000\n",
      "Iteration: 4701, Training Loss: 0.0184, Training Accuracy: 0.9922\n",
      "Iteration: 4711, Training Loss: 0.0016, Training Accuracy: 1.0000\n",
      "Iteration: 4721, Training Loss: 0.0027, Training Accuracy: 1.0000\n",
      "Iteration: 4731, Training Loss: 0.0040, Training Accuracy: 1.0000\n",
      "Iteration: 4741, Training Loss: 0.0117, Training Accuracy: 1.0000\n",
      "Iteration: 4751, Training Loss: 0.0035, Training Accuracy: 1.0000\n",
      "Iteration: 4761, Training Loss: 0.0101, Training Accuracy: 1.0000\n",
      "Iteration: 4771, Training Loss: 0.0077, Training Accuracy: 1.0000\n",
      "Iteration: 4781, Training Loss: 0.0206, Training Accuracy: 0.9922\n",
      "Iteration: 4791, Training Loss: 0.0119, Training Accuracy: 1.0000\n",
      "Iteration: 4801, Training Loss: 0.0034, Training Accuracy: 1.0000\n",
      "Iteration: 4811, Training Loss: 0.0020, Training Accuracy: 1.0000\n",
      "Iteration: 4821, Training Loss: 0.0057, Training Accuracy: 1.0000\n",
      "Iteration: 4831, Training Loss: 0.0046, Training Accuracy: 1.0000\n",
      "Iteration: 4841, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 4851, Training Loss: 0.0144, Training Accuracy: 0.9922\n",
      "Iteration: 4861, Training Loss: 0.0031, Training Accuracy: 1.0000\n",
      "Iteration: 4871, Training Loss: 0.0083, Training Accuracy: 1.0000\n",
      "Iteration: 4881, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 4891, Training Loss: 0.0035, Training Accuracy: 1.0000\n",
      "Iteration: 4901, Training Loss: 0.0036, Training Accuracy: 1.0000\n",
      "Iteration: 4911, Training Loss: 0.0023, Training Accuracy: 1.0000\n",
      "Iteration: 4921, Training Loss: 0.0305, Training Accuracy: 0.9844\n",
      "Iteration: 4931, Training Loss: 0.0047, Training Accuracy: 1.0000\n",
      "Iteration: 4941, Training Loss: 0.0069, Training Accuracy: 1.0000\n",
      "Iteration: 4951, Training Loss: 0.0038, Training Accuracy: 1.0000\n",
      "Iteration: 4961, Training Loss: 0.0035, Training Accuracy: 1.0000\n",
      "Iteration: 4971, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 4981, Training Loss: 0.0122, Training Accuracy: 0.9922\n",
      "Iteration: 4991, Training Loss: 0.0286, Training Accuracy: 0.9844\n",
      "Iteration: 5001, Training Loss: 0.0029, Training Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5011, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 5021, Training Loss: 0.0030, Training Accuracy: 1.0000\n",
      "Iteration: 5031, Training Loss: 0.0080, Training Accuracy: 1.0000\n",
      "Iteration: 5041, Training Loss: 0.0201, Training Accuracy: 0.9922\n",
      "Iteration: 5051, Training Loss: 0.0017, Training Accuracy: 1.0000\n",
      "Iteration: 5061, Training Loss: 0.0015, Training Accuracy: 1.0000\n",
      "Iteration: 5071, Training Loss: 0.0017, Training Accuracy: 1.0000\n",
      "Iteration: 5081, Training Loss: 0.0152, Training Accuracy: 0.9922\n",
      "Iteration: 5091, Training Loss: 0.0033, Training Accuracy: 1.0000\n",
      "Iteration: 5101, Training Loss: 0.0129, Training Accuracy: 0.9922\n",
      "Iteration: 5111, Training Loss: 0.0031, Training Accuracy: 1.0000\n",
      "Iteration: 5121, Training Loss: 0.0072, Training Accuracy: 1.0000\n",
      "Iteration: 5131, Training Loss: 0.0063, Training Accuracy: 1.0000\n",
      "Iteration: 5141, Training Loss: 0.0156, Training Accuracy: 0.9922\n",
      "Iteration: 5151, Training Loss: 0.0125, Training Accuracy: 0.9922\n",
      "Iteration: 5161, Training Loss: 0.0163, Training Accuracy: 1.0000\n",
      "Iteration: 5171, Training Loss: 0.0044, Training Accuracy: 1.0000\n",
      "Iteration: 5181, Training Loss: 0.0040, Training Accuracy: 1.0000\n",
      "Iteration: 5191, Training Loss: 0.0068, Training Accuracy: 1.0000\n",
      "Iteration: 5201, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 5211, Training Loss: 0.0025, Training Accuracy: 1.0000\n",
      "Iteration: 5221, Training Loss: 0.0025, Training Accuracy: 1.0000\n",
      "Iteration: 5231, Training Loss: 0.0046, Training Accuracy: 1.0000\n",
      "Iteration: 5241, Training Loss: 0.0029, Training Accuracy: 1.0000\n",
      "Iteration: 5251, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 5261, Training Loss: 0.0021, Training Accuracy: 1.0000\n",
      "Iteration: 5271, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 5281, Training Loss: 0.0138, Training Accuracy: 0.9922\n",
      "Iteration: 5291, Training Loss: 0.0095, Training Accuracy: 1.0000\n",
      "Iteration: 5301, Training Loss: 0.0048, Training Accuracy: 1.0000\n",
      "Iteration: 5311, Training Loss: 0.0356, Training Accuracy: 0.9922\n",
      "Iteration: 5321, Training Loss: 0.0064, Training Accuracy: 1.0000\n",
      "Iteration: 5331, Training Loss: 0.0111, Training Accuracy: 0.9922\n",
      "Iteration: 5341, Training Loss: 0.0240, Training Accuracy: 0.9922\n",
      "Iteration: 5351, Training Loss: 0.0050, Training Accuracy: 1.0000\n",
      "Iteration: 5361, Training Loss: 0.0216, Training Accuracy: 0.9922\n",
      "Iteration: 5371, Training Loss: 0.0126, Training Accuracy: 0.9922\n",
      "Iteration: 5381, Training Loss: 0.0073, Training Accuracy: 0.9922\n",
      "Iteration: 5391, Training Loss: 0.0089, Training Accuracy: 0.9922\n",
      "Iteration: 5401, Training Loss: 0.0038, Training Accuracy: 1.0000\n",
      "Iteration: 5411, Training Loss: 0.0022, Training Accuracy: 1.0000\n",
      "Iteration: 5421, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 5431, Training Loss: 0.0026, Training Accuracy: 1.0000\n",
      "Iteration: 5441, Training Loss: 0.0059, Training Accuracy: 1.0000\n",
      "Iteration: 5451, Training Loss: 0.0057, Training Accuracy: 1.0000\n",
      "Iteration: 5461, Training Loss: 0.0041, Training Accuracy: 1.0000\n",
      "Iteration: 5471, Training Loss: 0.0099, Training Accuracy: 1.0000\n",
      "Iteration: 5481, Training Loss: 0.0100, Training Accuracy: 0.9922\n",
      "Iteration: 5491, Training Loss: 0.0051, Training Accuracy: 1.0000\n",
      "Iteration: 5501, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 5511, Training Loss: 0.0068, Training Accuracy: 1.0000\n",
      "Iteration: 5521, Training Loss: 0.0261, Training Accuracy: 0.9922\n",
      "Iteration: 5531, Training Loss: 0.0032, Training Accuracy: 1.0000\n",
      "Iteration: 5541, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 5551, Training Loss: 0.0017, Training Accuracy: 1.0000\n",
      "Iteration: 5561, Training Loss: 0.0022, Training Accuracy: 1.0000\n",
      "Iteration: 5571, Training Loss: 0.0041, Training Accuracy: 1.0000\n",
      "Iteration: 5581, Training Loss: 0.0028, Training Accuracy: 1.0000\n",
      "Iteration: 5591, Training Loss: 0.0022, Training Accuracy: 1.0000\n",
      "Iteration: 5601, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 5611, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 5621, Training Loss: 0.0028, Training Accuracy: 1.0000\n",
      "Iteration: 5631, Training Loss: 0.0038, Training Accuracy: 1.0000\n",
      "Iteration: 5641, Training Loss: 0.0097, Training Accuracy: 1.0000\n",
      "Iteration: 5651, Training Loss: 0.0090, Training Accuracy: 1.0000\n",
      "Iteration: 5661, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 5671, Training Loss: 0.0397, Training Accuracy: 0.9844\n",
      "Iteration: 5681, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 5691, Training Loss: 0.0043, Training Accuracy: 1.0000\n",
      "Iteration: 5701, Training Loss: 0.0164, Training Accuracy: 0.9922\n",
      "Iteration: 5711, Training Loss: 0.0036, Training Accuracy: 1.0000\n",
      "Iteration: 5721, Training Loss: 0.0064, Training Accuracy: 0.9922\n",
      "Iteration: 5731, Training Loss: 0.0590, Training Accuracy: 0.9922\n",
      "Iteration: 5741, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 5751, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 5761, Training Loss: 0.0083, Training Accuracy: 1.0000\n",
      "Iteration: 5771, Training Loss: 0.0127, Training Accuracy: 0.9922\n",
      "Iteration: 5781, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 5791, Training Loss: 0.0031, Training Accuracy: 1.0000\n",
      "Iteration: 5801, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 5811, Training Loss: 0.0104, Training Accuracy: 1.0000\n",
      "Iteration: 5821, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 5831, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 5841, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 5851, Training Loss: 0.0015, Training Accuracy: 1.0000\n",
      "Iteration: 5861, Training Loss: 0.0113, Training Accuracy: 0.9922\n",
      "Iteration: 5871, Training Loss: 0.0029, Training Accuracy: 1.0000\n",
      "Iteration: 5881, Training Loss: 0.0068, Training Accuracy: 1.0000\n",
      "Iteration: 5891, Training Loss: 0.0082, Training Accuracy: 1.0000\n",
      "Iteration: 5901, Training Loss: 0.0068, Training Accuracy: 1.0000\n",
      "Iteration: 5911, Training Loss: 0.0050, Training Accuracy: 1.0000\n",
      "Iteration: 5921, Training Loss: 0.0085, Training Accuracy: 0.9922\n",
      "Iteration: 5931, Training Loss: 0.0128, Training Accuracy: 0.9922\n",
      "Iteration: 5941, Training Loss: 0.0021, Training Accuracy: 1.0000\n",
      "Iteration: 5951, Training Loss: 0.0053, Training Accuracy: 1.0000\n",
      "Iteration: 5961, Training Loss: 0.0091, Training Accuracy: 0.9922\n",
      "Iteration: 5971, Training Loss: 0.0021, Training Accuracy: 1.0000\n",
      "Iteration: 5981, Training Loss: 0.0016, Training Accuracy: 1.0000\n",
      "Iteration: 5991, Training Loss: 0.0076, Training Accuracy: 1.0000\n",
      "Iteration: 6001, Training Loss: 0.0069, Training Accuracy: 1.0000\n",
      "Iteration: 6011, Training Loss: 0.0451, Training Accuracy: 0.9844\n",
      "Iteration: 6021, Training Loss: 0.0053, Training Accuracy: 1.0000\n",
      "Iteration: 6031, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 6041, Training Loss: 0.0049, Training Accuracy: 1.0000\n",
      "Iteration: 6051, Training Loss: 0.0266, Training Accuracy: 0.9922\n",
      "Iteration: 6061, Training Loss: 0.0021, Training Accuracy: 1.0000\n",
      "Iteration: 6071, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 6081, Training Loss: 0.0044, Training Accuracy: 1.0000\n",
      "Iteration: 6091, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 6101, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 6111, Training Loss: 0.0025, Training Accuracy: 1.0000\n",
      "Iteration: 6121, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 6131, Training Loss: 0.0021, Training Accuracy: 1.0000\n",
      "Iteration: 6141, Training Loss: 0.0198, Training Accuracy: 0.9922\n",
      "Iteration: 6151, Training Loss: 0.0033, Training Accuracy: 1.0000\n",
      "Iteration: 6161, Training Loss: 0.0026, Training Accuracy: 1.0000\n",
      "Iteration: 6171, Training Loss: 0.0032, Training Accuracy: 1.0000\n",
      "Iteration: 6181, Training Loss: 0.0235, Training Accuracy: 0.9922\n",
      "Iteration: 6191, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 6201, Training Loss: 0.0019, Training Accuracy: 1.0000\n",
      "Iteration: 6211, Training Loss: 0.0022, Training Accuracy: 1.0000\n",
      "Iteration: 6221, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 6231, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 6241, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 6251, Training Loss: 0.0037, Training Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6261, Training Loss: 0.0051, Training Accuracy: 1.0000\n",
      "Iteration: 6271, Training Loss: 0.0024, Training Accuracy: 1.0000\n",
      "Iteration: 6281, Training Loss: 0.0203, Training Accuracy: 0.9922\n",
      "Iteration: 6291, Training Loss: 0.0088, Training Accuracy: 0.9922\n",
      "Iteration: 6301, Training Loss: 0.0050, Training Accuracy: 1.0000\n",
      "Iteration: 6311, Training Loss: 0.0065, Training Accuracy: 0.9922\n",
      "Iteration: 6321, Training Loss: 0.0068, Training Accuracy: 0.9922\n",
      "Iteration: 6331, Training Loss: 0.0042, Training Accuracy: 1.0000\n",
      "Iteration: 6341, Training Loss: 0.0025, Training Accuracy: 1.0000\n",
      "Iteration: 6351, Training Loss: 0.0089, Training Accuracy: 1.0000\n",
      "Iteration: 6361, Training Loss: 0.0045, Training Accuracy: 1.0000\n",
      "Iteration: 6371, Training Loss: 0.0015, Training Accuracy: 1.0000\n",
      "Iteration: 6381, Training Loss: 0.0080, Training Accuracy: 1.0000\n",
      "Iteration: 6391, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 6401, Training Loss: 0.0053, Training Accuracy: 1.0000\n",
      "Iteration: 6411, Training Loss: 0.0049, Training Accuracy: 1.0000\n",
      "Iteration: 6421, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 6431, Training Loss: 0.0132, Training Accuracy: 0.9922\n",
      "Iteration: 6441, Training Loss: 0.0019, Training Accuracy: 1.0000\n",
      "Iteration: 6451, Training Loss: 0.0304, Training Accuracy: 0.9922\n",
      "Iteration: 6461, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 6471, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 6481, Training Loss: 0.0016, Training Accuracy: 1.0000\n",
      "Iteration: 6491, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 6501, Training Loss: 0.0017, Training Accuracy: 1.0000\n",
      "Iteration: 6511, Training Loss: 0.0083, Training Accuracy: 0.9922\n",
      "Iteration: 6521, Training Loss: 0.0062, Training Accuracy: 1.0000\n",
      "Iteration: 6531, Training Loss: 0.0037, Training Accuracy: 1.0000\n",
      "Iteration: 6541, Training Loss: 0.0015, Training Accuracy: 1.0000\n",
      "Iteration: 6551, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 6561, Training Loss: 0.0078, Training Accuracy: 0.9922\n",
      "Iteration: 6571, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 6581, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 6591, Training Loss: 0.0071, Training Accuracy: 1.0000\n",
      "Iteration: 6601, Training Loss: 0.0063, Training Accuracy: 1.0000\n",
      "Iteration: 6611, Training Loss: 0.0024, Training Accuracy: 1.0000\n",
      "Iteration: 6621, Training Loss: 0.0039, Training Accuracy: 1.0000\n",
      "Iteration: 6631, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 6641, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 6651, Training Loss: 0.0057, Training Accuracy: 1.0000\n",
      "Iteration: 6661, Training Loss: 0.0028, Training Accuracy: 1.0000\n",
      "Iteration: 6671, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 6681, Training Loss: 0.0018, Training Accuracy: 1.0000\n",
      "Iteration: 6691, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 6701, Training Loss: 0.0108, Training Accuracy: 1.0000\n",
      "Iteration: 6711, Training Loss: 0.0044, Training Accuracy: 1.0000\n",
      "Iteration: 6721, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 6731, Training Loss: 0.0227, Training Accuracy: 0.9922\n",
      "Iteration: 6741, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 6751, Training Loss: 0.0144, Training Accuracy: 0.9922\n",
      "Iteration: 6761, Training Loss: 0.0070, Training Accuracy: 0.9922\n",
      "Iteration: 6771, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 6781, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 6791, Training Loss: 0.0022, Training Accuracy: 1.0000\n",
      "Iteration: 6801, Training Loss: 0.0025, Training Accuracy: 1.0000\n",
      "Iteration: 6811, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 6821, Training Loss: 0.0202, Training Accuracy: 0.9922\n",
      "Iteration: 6831, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 6841, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 6851, Training Loss: 0.0020, Training Accuracy: 1.0000\n",
      "Iteration: 6861, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 6871, Training Loss: 0.0041, Training Accuracy: 1.0000\n",
      "Iteration: 6881, Training Loss: 0.0130, Training Accuracy: 0.9922\n",
      "Iteration: 6891, Training Loss: 0.0025, Training Accuracy: 1.0000\n",
      "Iteration: 6901, Training Loss: 0.0030, Training Accuracy: 1.0000\n",
      "Iteration: 6911, Training Loss: 0.0162, Training Accuracy: 0.9922\n",
      "Iteration: 6921, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 6931, Training Loss: 0.0060, Training Accuracy: 1.0000\n",
      "Iteration: 6941, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 6951, Training Loss: 0.0040, Training Accuracy: 1.0000\n",
      "Iteration: 6961, Training Loss: 0.0128, Training Accuracy: 0.9922\n",
      "Iteration: 6971, Training Loss: 0.0040, Training Accuracy: 1.0000\n",
      "Iteration: 6981, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 6991, Training Loss: 0.0027, Training Accuracy: 1.0000\n",
      "Iteration: 7001, Training Loss: 0.0024, Training Accuracy: 1.0000\n",
      "Iteration: 7011, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 7021, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 7031, Training Loss: 0.0074, Training Accuracy: 1.0000\n",
      "Iteration: 7041, Training Loss: 0.0029, Training Accuracy: 1.0000\n",
      "Iteration: 7051, Training Loss: 0.0084, Training Accuracy: 1.0000\n",
      "Iteration: 7061, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 7071, Training Loss: 0.0176, Training Accuracy: 0.9922\n",
      "Iteration: 7081, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 7091, Training Loss: 0.0026, Training Accuracy: 1.0000\n",
      "Iteration: 7101, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 7111, Training Loss: 0.0038, Training Accuracy: 1.0000\n",
      "Iteration: 7121, Training Loss: 0.0033, Training Accuracy: 1.0000\n",
      "Iteration: 7131, Training Loss: 0.0047, Training Accuracy: 1.0000\n",
      "Iteration: 7141, Training Loss: 0.0048, Training Accuracy: 1.0000\n",
      "Iteration: 7151, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 7161, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 7171, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 7181, Training Loss: 0.0040, Training Accuracy: 1.0000\n",
      "Iteration: 7191, Training Loss: 0.0019, Training Accuracy: 1.0000\n",
      "Iteration: 7201, Training Loss: 0.0132, Training Accuracy: 0.9922\n",
      "Iteration: 7211, Training Loss: 0.0029, Training Accuracy: 1.0000\n",
      "Iteration: 7221, Training Loss: 0.0054, Training Accuracy: 1.0000\n",
      "Iteration: 7231, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 7241, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 7251, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 7261, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 7271, Training Loss: 0.0037, Training Accuracy: 1.0000\n",
      "Iteration: 7281, Training Loss: 0.0018, Training Accuracy: 1.0000\n",
      "Iteration: 7291, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 7301, Training Loss: 0.0110, Training Accuracy: 0.9922\n",
      "Iteration: 7311, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 7321, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 7331, Training Loss: 0.0079, Training Accuracy: 0.9922\n",
      "Iteration: 7341, Training Loss: 0.0054, Training Accuracy: 1.0000\n",
      "Iteration: 7351, Training Loss: 0.0048, Training Accuracy: 1.0000\n",
      "Iteration: 7361, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 7371, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 7381, Training Loss: 0.0280, Training Accuracy: 0.9844\n",
      "Iteration: 7391, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 7401, Training Loss: 0.0079, Training Accuracy: 1.0000\n",
      "Iteration: 7411, Training Loss: 0.0033, Training Accuracy: 1.0000\n",
      "Iteration: 7421, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 7431, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 7441, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 7451, Training Loss: 0.0054, Training Accuracy: 1.0000\n",
      "Iteration: 7461, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 7471, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 7481, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 7491, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 7501, Training Loss: 0.0042, Training Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7511, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 7521, Training Loss: 0.0020, Training Accuracy: 1.0000\n",
      "Iteration: 7531, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 7541, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 7551, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 7561, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 7571, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 7581, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 7591, Training Loss: 0.0068, Training Accuracy: 1.0000\n",
      "Iteration: 7601, Training Loss: 0.0051, Training Accuracy: 1.0000\n",
      "Iteration: 7611, Training Loss: 0.0023, Training Accuracy: 1.0000\n",
      "Iteration: 7621, Training Loss: 0.0019, Training Accuracy: 1.0000\n",
      "Iteration: 7631, Training Loss: 0.0030, Training Accuracy: 1.0000\n",
      "Iteration: 7641, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 7651, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 7661, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 7671, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 7681, Training Loss: 0.0132, Training Accuracy: 0.9922\n",
      "Iteration: 7691, Training Loss: 0.0038, Training Accuracy: 1.0000\n",
      "Iteration: 7701, Training Loss: 0.0017, Training Accuracy: 1.0000\n",
      "Iteration: 7711, Training Loss: 0.0043, Training Accuracy: 1.0000\n",
      "Iteration: 7721, Training Loss: 0.0326, Training Accuracy: 0.9922\n",
      "Iteration: 7731, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 7741, Training Loss: 0.0038, Training Accuracy: 1.0000\n",
      "Iteration: 7751, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 7761, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 7771, Training Loss: 0.0017, Training Accuracy: 1.0000\n",
      "Iteration: 7781, Training Loss: 0.0027, Training Accuracy: 1.0000\n",
      "Iteration: 7791, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 7801, Training Loss: 0.0017, Training Accuracy: 1.0000\n",
      "Iteration: 7811, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 7821, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 7831, Training Loss: 0.0109, Training Accuracy: 0.9922\n",
      "Iteration: 7841, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 7851, Training Loss: 0.0016, Training Accuracy: 1.0000\n",
      "Iteration: 7861, Training Loss: 0.0077, Training Accuracy: 0.9922\n",
      "Iteration: 7871, Training Loss: 0.0097, Training Accuracy: 0.9922\n",
      "Iteration: 7881, Training Loss: 0.0165, Training Accuracy: 0.9922\n",
      "Iteration: 7891, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 7901, Training Loss: 0.0107, Training Accuracy: 1.0000\n",
      "Iteration: 7911, Training Loss: 0.0017, Training Accuracy: 1.0000\n",
      "Iteration: 7921, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 7931, Training Loss: 0.0044, Training Accuracy: 1.0000\n",
      "Iteration: 7941, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 7951, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 7961, Training Loss: 0.0016, Training Accuracy: 1.0000\n",
      "Iteration: 7971, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 7981, Training Loss: 0.0135, Training Accuracy: 0.9922\n",
      "Iteration: 7991, Training Loss: 0.0016, Training Accuracy: 1.0000\n",
      "Iteration: 8001, Training Loss: 0.0054, Training Accuracy: 1.0000\n",
      "Iteration: 8011, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 8021, Training Loss: 0.0078, Training Accuracy: 0.9922\n",
      "Iteration: 8031, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 8041, Training Loss: 0.0113, Training Accuracy: 0.9922\n",
      "Iteration: 8051, Training Loss: 0.0181, Training Accuracy: 0.9922\n",
      "Iteration: 8061, Training Loss: 0.0069, Training Accuracy: 1.0000\n",
      "Iteration: 8071, Training Loss: 0.0128, Training Accuracy: 0.9844\n",
      "Iteration: 8081, Training Loss: 0.0023, Training Accuracy: 1.0000\n",
      "Iteration: 8091, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 8101, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 8111, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 8121, Training Loss: 0.0113, Training Accuracy: 0.9922\n",
      "Iteration: 8131, Training Loss: 0.0039, Training Accuracy: 1.0000\n",
      "Iteration: 8141, Training Loss: 0.0192, Training Accuracy: 0.9922\n",
      "Iteration: 8151, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 8161, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 8171, Training Loss: 0.0033, Training Accuracy: 1.0000\n",
      "Iteration: 8181, Training Loss: 0.0016, Training Accuracy: 1.0000\n",
      "Iteration: 8191, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 8201, Training Loss: 0.0082, Training Accuracy: 1.0000\n",
      "Iteration: 8211, Training Loss: 0.0025, Training Accuracy: 1.0000\n",
      "Iteration: 8221, Training Loss: 0.0150, Training Accuracy: 0.9922\n",
      "Iteration: 8231, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 8241, Training Loss: 0.0026, Training Accuracy: 1.0000\n",
      "Iteration: 8251, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 8261, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 8271, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 8281, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 8291, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 8301, Training Loss: 0.0025, Training Accuracy: 1.0000\n",
      "Iteration: 8311, Training Loss: 0.0027, Training Accuracy: 1.0000\n",
      "Iteration: 8321, Training Loss: 0.0031, Training Accuracy: 1.0000\n",
      "Iteration: 8331, Training Loss: 0.0036, Training Accuracy: 1.0000\n",
      "Iteration: 8341, Training Loss: 0.0028, Training Accuracy: 1.0000\n",
      "Iteration: 8351, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 8361, Training Loss: 0.0112, Training Accuracy: 0.9922\n",
      "Iteration: 8371, Training Loss: 0.0034, Training Accuracy: 1.0000\n",
      "Iteration: 8381, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 8391, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 8401, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 8411, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 8421, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 8431, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 8441, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 8451, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 8461, Training Loss: 0.0240, Training Accuracy: 0.9922\n",
      "Iteration: 8471, Training Loss: 0.0142, Training Accuracy: 0.9922\n",
      "Iteration: 8481, Training Loss: 0.0017, Training Accuracy: 1.0000\n",
      "Iteration: 8491, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 8501, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 8511, Training Loss: 0.0120, Training Accuracy: 0.9922\n",
      "Iteration: 8521, Training Loss: 0.0109, Training Accuracy: 0.9922\n",
      "Iteration: 8531, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 8541, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 8551, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 8561, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 8571, Training Loss: 0.0022, Training Accuracy: 1.0000\n",
      "Iteration: 8581, Training Loss: 0.0136, Training Accuracy: 0.9922\n",
      "Iteration: 8591, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 8601, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 8611, Training Loss: 0.0019, Training Accuracy: 1.0000\n",
      "Iteration: 8621, Training Loss: 0.0024, Training Accuracy: 1.0000\n",
      "Iteration: 8631, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 8641, Training Loss: 0.0030, Training Accuracy: 1.0000\n",
      "Iteration: 8651, Training Loss: 0.0434, Training Accuracy: 0.9922\n",
      "Iteration: 8661, Training Loss: 0.0027, Training Accuracy: 1.0000\n",
      "Iteration: 8671, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 8681, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 8691, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 8701, Training Loss: 0.0021, Training Accuracy: 1.0000\n",
      "Iteration: 8711, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 8721, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 8731, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 8741, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 8751, Training Loss: 0.0005, Training Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 8761, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 8771, Training Loss: 0.0109, Training Accuracy: 0.9922\n",
      "Iteration: 8781, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 8791, Training Loss: 0.0083, Training Accuracy: 0.9922\n",
      "Iteration: 8801, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 8811, Training Loss: 0.0030, Training Accuracy: 1.0000\n",
      "Iteration: 8821, Training Loss: 0.0031, Training Accuracy: 1.0000\n",
      "Iteration: 8831, Training Loss: 0.0016, Training Accuracy: 1.0000\n",
      "Iteration: 8841, Training Loss: 0.0030, Training Accuracy: 1.0000\n",
      "Iteration: 8851, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 8861, Training Loss: 0.0030, Training Accuracy: 1.0000\n",
      "Iteration: 8871, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 8881, Training Loss: 0.0090, Training Accuracy: 0.9922\n",
      "Iteration: 8891, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 8901, Training Loss: 0.0024, Training Accuracy: 1.0000\n",
      "Iteration: 8911, Training Loss: 0.0028, Training Accuracy: 1.0000\n",
      "Iteration: 8921, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 8931, Training Loss: 0.0061, Training Accuracy: 1.0000\n",
      "Iteration: 8941, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 8951, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 8961, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 8971, Training Loss: 0.0051, Training Accuracy: 1.0000\n",
      "Iteration: 8981, Training Loss: 0.0058, Training Accuracy: 1.0000\n",
      "Iteration: 8991, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 9001, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 9011, Training Loss: 0.0102, Training Accuracy: 0.9922\n",
      "Iteration: 9021, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 9031, Training Loss: 0.0019, Training Accuracy: 1.0000\n",
      "Iteration: 9041, Training Loss: 0.0044, Training Accuracy: 1.0000\n",
      "Iteration: 9051, Training Loss: 0.0124, Training Accuracy: 0.9922\n",
      "Iteration: 9061, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 9071, Training Loss: 0.0089, Training Accuracy: 1.0000\n",
      "Iteration: 9081, Training Loss: 0.0029, Training Accuracy: 1.0000\n",
      "Iteration: 9091, Training Loss: 0.0024, Training Accuracy: 1.0000\n",
      "Iteration: 9101, Training Loss: 0.0021, Training Accuracy: 1.0000\n",
      "Iteration: 9111, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 9121, Training Loss: 0.0079, Training Accuracy: 1.0000\n",
      "Iteration: 9131, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 9141, Training Loss: 0.0254, Training Accuracy: 0.9922\n",
      "Iteration: 9151, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 9161, Training Loss: 0.0017, Training Accuracy: 1.0000\n",
      "Iteration: 9171, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 9181, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 9191, Training Loss: 0.0043, Training Accuracy: 1.0000\n",
      "Iteration: 9201, Training Loss: 0.0047, Training Accuracy: 1.0000\n",
      "Iteration: 9211, Training Loss: 0.0021, Training Accuracy: 1.0000\n",
      "Iteration: 9221, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 9231, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 9241, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 9251, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 9261, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 9271, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 9281, Training Loss: 0.0263, Training Accuracy: 0.9922\n",
      "Iteration: 9291, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 9301, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 9311, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 9321, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 9331, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 9341, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 9351, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 9361, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 9371, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 9381, Training Loss: 0.0035, Training Accuracy: 1.0000\n",
      "Iteration: 9391, Training Loss: 0.0049, Training Accuracy: 1.0000\n",
      "Iteration: 9401, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 9411, Training Loss: 0.0027, Training Accuracy: 1.0000\n",
      "Iteration: 9421, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 9431, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 9441, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 9451, Training Loss: 0.0029, Training Accuracy: 1.0000\n",
      "Iteration: 9461, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 9471, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 9481, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 9491, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 9501, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 9511, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 9521, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 9531, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 9541, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 9551, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 9561, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 9571, Training Loss: 0.0027, Training Accuracy: 1.0000\n",
      "Iteration: 9581, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 9591, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 9601, Training Loss: 0.0015, Training Accuracy: 1.0000\n",
      "Iteration: 9611, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 9621, Training Loss: 0.0032, Training Accuracy: 1.0000\n",
      "Iteration: 9631, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 9641, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 9651, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 9661, Training Loss: 0.0199, Training Accuracy: 0.9922\n",
      "Iteration: 9671, Training Loss: 0.0033, Training Accuracy: 1.0000\n",
      "Iteration: 9681, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 9691, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 9701, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 9711, Training Loss: 0.0051, Training Accuracy: 1.0000\n",
      "Iteration: 9721, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 9731, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 9741, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 9751, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 9761, Training Loss: 0.0073, Training Accuracy: 1.0000\n",
      "Iteration: 9771, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 9781, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 9791, Training Loss: 0.0037, Training Accuracy: 1.0000\n",
      "Iteration: 9801, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 9811, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 9821, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 9831, Training Loss: 0.0016, Training Accuracy: 1.0000\n",
      "Iteration: 9841, Training Loss: 0.0028, Training Accuracy: 1.0000\n",
      "Iteration: 9851, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 9861, Training Loss: 0.0023, Training Accuracy: 1.0000\n",
      "Iteration: 9871, Training Loss: 0.0041, Training Accuracy: 1.0000\n",
      "Iteration: 9881, Training Loss: 0.0050, Training Accuracy: 1.0000\n",
      "Iteration: 9891, Training Loss: 0.0042, Training Accuracy: 1.0000\n",
      "Iteration: 9901, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 9911, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 9921, Training Loss: 0.0175, Training Accuracy: 0.9922\n",
      "Iteration: 9931, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 9941, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 9951, Training Loss: 0.0025, Training Accuracy: 1.0000\n",
      "Iteration: 9961, Training Loss: 0.0368, Training Accuracy: 0.9922\n",
      "Iteration: 9971, Training Loss: 0.0037, Training Accuracy: 1.0000\n",
      "Iteration: 9981, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 9991, Training Loss: 0.0028, Training Accuracy: 1.0000\n",
      "Iteration: 10001, Training Loss: 0.0008, Training Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10011, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 10021, Training Loss: 0.0019, Training Accuracy: 1.0000\n",
      "Iteration: 10031, Training Loss: 0.0019, Training Accuracy: 1.0000\n",
      "Iteration: 10041, Training Loss: 0.0068, Training Accuracy: 1.0000\n",
      "Iteration: 10051, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 10061, Training Loss: 0.0022, Training Accuracy: 1.0000\n",
      "Iteration: 10071, Training Loss: 0.0018, Training Accuracy: 1.0000\n",
      "Iteration: 10081, Training Loss: 0.0034, Training Accuracy: 1.0000\n",
      "Iteration: 10091, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 10101, Training Loss: 0.0237, Training Accuracy: 0.9922\n",
      "Iteration: 10111, Training Loss: 0.0020, Training Accuracy: 1.0000\n",
      "Iteration: 10121, Training Loss: 0.0029, Training Accuracy: 1.0000\n",
      "Iteration: 10131, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 10141, Training Loss: 0.0025, Training Accuracy: 1.0000\n",
      "Iteration: 10151, Training Loss: 0.0076, Training Accuracy: 0.9922\n",
      "Iteration: 10161, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 10171, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 10181, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 10191, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 10201, Training Loss: 0.0087, Training Accuracy: 0.9922\n",
      "Iteration: 10211, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 10221, Training Loss: 0.0025, Training Accuracy: 1.0000\n",
      "Iteration: 10231, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 10241, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 10251, Training Loss: 0.0171, Training Accuracy: 0.9922\n",
      "Iteration: 10261, Training Loss: 0.0022, Training Accuracy: 1.0000\n",
      "Iteration: 10271, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 10281, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 10291, Training Loss: 0.0050, Training Accuracy: 1.0000\n",
      "Iteration: 10301, Training Loss: 0.0110, Training Accuracy: 0.9922\n",
      "Iteration: 10311, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 10321, Training Loss: 0.0027, Training Accuracy: 1.0000\n",
      "Iteration: 10331, Training Loss: 0.0016, Training Accuracy: 1.0000\n",
      "Iteration: 10341, Training Loss: 0.0018, Training Accuracy: 1.0000\n",
      "Iteration: 10351, Training Loss: 0.0054, Training Accuracy: 1.0000\n",
      "Iteration: 10361, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 10371, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 10381, Training Loss: 0.0100, Training Accuracy: 0.9922\n",
      "Iteration: 10391, Training Loss: 0.0026, Training Accuracy: 1.0000\n",
      "Iteration: 10401, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 10411, Training Loss: 0.0035, Training Accuracy: 1.0000\n",
      "Iteration: 10421, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 10431, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 10441, Training Loss: 0.0022, Training Accuracy: 1.0000\n",
      "Iteration: 10451, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 10461, Training Loss: 0.0056, Training Accuracy: 1.0000\n",
      "Iteration: 10471, Training Loss: 0.0035, Training Accuracy: 1.0000\n",
      "Iteration: 10481, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 10491, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 10501, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 10511, Training Loss: 0.0078, Training Accuracy: 0.9922\n",
      "Iteration: 10521, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 10531, Training Loss: 0.0291, Training Accuracy: 0.9922\n",
      "Iteration: 10541, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 10551, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 10561, Training Loss: 0.0018, Training Accuracy: 1.0000\n",
      "Iteration: 10571, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 10581, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 10591, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 10601, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 10611, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 10621, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 10631, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 10641, Training Loss: 0.0175, Training Accuracy: 0.9922\n",
      "Iteration: 10651, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 10661, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 10671, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 10681, Training Loss: 0.0072, Training Accuracy: 1.0000\n",
      "Iteration: 10691, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 10701, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 10711, Training Loss: 0.0041, Training Accuracy: 1.0000\n",
      "Iteration: 10721, Training Loss: 0.0051, Training Accuracy: 1.0000\n",
      "Iteration: 10731, Training Loss: 0.0015, Training Accuracy: 1.0000\n",
      "Iteration: 10741, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 10751, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 10761, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 10771, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 10781, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 10791, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 10801, Training Loss: 0.0029, Training Accuracy: 1.0000\n",
      "Iteration: 10811, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 10821, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 10831, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 10841, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 10851, Training Loss: 0.0071, Training Accuracy: 1.0000\n",
      "Iteration: 10861, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 10871, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 10881, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 10891, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 10901, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 10911, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 10921, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 10931, Training Loss: 0.0020, Training Accuracy: 1.0000\n",
      "Iteration: 10941, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 10951, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 10961, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 10971, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 10981, Training Loss: 0.0037, Training Accuracy: 1.0000\n",
      "Iteration: 10991, Training Loss: 0.0021, Training Accuracy: 1.0000\n",
      "Iteration: 11001, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 11011, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 11021, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 11031, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 11041, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 11051, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 11061, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 11071, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 11081, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 11091, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 11101, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 11111, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 11121, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 11131, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 11141, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 11151, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 11161, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 11171, Training Loss: 0.0035, Training Accuracy: 1.0000\n",
      "Iteration: 11181, Training Loss: 0.0018, Training Accuracy: 1.0000\n",
      "Iteration: 11191, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 11201, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 11211, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 11221, Training Loss: 0.0017, Training Accuracy: 1.0000\n",
      "Iteration: 11231, Training Loss: 0.0001, Training Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 11241, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 11251, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 11261, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 11271, Training Loss: 0.0025, Training Accuracy: 1.0000\n",
      "Iteration: 11281, Training Loss: 0.0062, Training Accuracy: 1.0000\n",
      "Iteration: 11291, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 11301, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 11311, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 11321, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 11331, Training Loss: 0.0018, Training Accuracy: 1.0000\n",
      "Iteration: 11341, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 11351, Training Loss: 0.0015, Training Accuracy: 1.0000\n",
      "Iteration: 11361, Training Loss: 0.0039, Training Accuracy: 1.0000\n",
      "Iteration: 11371, Training Loss: 0.0027, Training Accuracy: 1.0000\n",
      "Iteration: 11381, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 11391, Training Loss: 0.0052, Training Accuracy: 1.0000\n",
      "Iteration: 11401, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 11411, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 11421, Training Loss: 0.0096, Training Accuracy: 0.9922\n",
      "Iteration: 11431, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 11441, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 11451, Training Loss: 0.0023, Training Accuracy: 1.0000\n",
      "Iteration: 11461, Training Loss: 0.0021, Training Accuracy: 1.0000\n",
      "Iteration: 11471, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 11481, Training Loss: 0.0016, Training Accuracy: 1.0000\n",
      "Iteration: 11491, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 11501, Training Loss: 0.0024, Training Accuracy: 1.0000\n",
      "Iteration: 11511, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 11521, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 11531, Training Loss: 0.0055, Training Accuracy: 1.0000\n",
      "Iteration: 11541, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 11551, Training Loss: 0.0107, Training Accuracy: 0.9922\n",
      "Iteration: 11561, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 11571, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 11581, Training Loss: 0.0015, Training Accuracy: 1.0000\n",
      "Iteration: 11591, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 11601, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 11611, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 11621, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 11631, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 11641, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 11651, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 11661, Training Loss: 0.0250, Training Accuracy: 0.9844\n",
      "Iteration: 11671, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 11681, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 11691, Training Loss: 0.0018, Training Accuracy: 1.0000\n",
      "Iteration: 11701, Training Loss: 0.0035, Training Accuracy: 1.0000\n",
      "Iteration: 11711, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 11721, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 11731, Training Loss: 0.0016, Training Accuracy: 1.0000\n",
      "Iteration: 11741, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 11751, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 11761, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 11771, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 11781, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 11791, Training Loss: 0.0069, Training Accuracy: 0.9922\n",
      "Iteration: 11801, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 11811, Training Loss: 0.0052, Training Accuracy: 1.0000\n",
      "Iteration: 11821, Training Loss: 0.0038, Training Accuracy: 1.0000\n",
      "Iteration: 11831, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 11841, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 11851, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 11861, Training Loss: 0.0017, Training Accuracy: 1.0000\n",
      "Iteration: 11871, Training Loss: 0.0017, Training Accuracy: 1.0000\n",
      "Iteration: 11881, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 11891, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 11901, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 11911, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 11921, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 11931, Training Loss: 0.0030, Training Accuracy: 1.0000\n",
      "Iteration: 11941, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 11951, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 11961, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 11971, Training Loss: 0.0158, Training Accuracy: 0.9922\n",
      "Iteration: 11981, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 11991, Training Loss: 0.0039, Training Accuracy: 1.0000\n",
      "Iteration: 12001, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 12011, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 12021, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 12031, Training Loss: 0.0049, Training Accuracy: 1.0000\n",
      "Iteration: 12041, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 12051, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 12061, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 12071, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 12081, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 12091, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 12101, Training Loss: 0.0035, Training Accuracy: 1.0000\n",
      "Iteration: 12111, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 12121, Training Loss: 0.0015, Training Accuracy: 1.0000\n",
      "Iteration: 12131, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 12141, Training Loss: 0.0015, Training Accuracy: 1.0000\n",
      "Iteration: 12151, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 12161, Training Loss: 0.0038, Training Accuracy: 1.0000\n",
      "Iteration: 12171, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 12181, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 12191, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 12201, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 12211, Training Loss: 0.0037, Training Accuracy: 1.0000\n",
      "Iteration: 12221, Training Loss: 0.0024, Training Accuracy: 1.0000\n",
      "Iteration: 12231, Training Loss: 0.0017, Training Accuracy: 1.0000\n",
      "Iteration: 12241, Training Loss: 0.0199, Training Accuracy: 0.9922\n",
      "Iteration: 12251, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 12261, Training Loss: 0.0049, Training Accuracy: 1.0000\n",
      "Iteration: 12271, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 12281, Training Loss: 0.0019, Training Accuracy: 1.0000\n",
      "Iteration: 12291, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 12301, Training Loss: 0.0015, Training Accuracy: 1.0000\n",
      "Iteration: 12311, Training Loss: 0.0029, Training Accuracy: 1.0000\n",
      "Iteration: 12321, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 12331, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 12341, Training Loss: 0.0264, Training Accuracy: 0.9844\n",
      "Iteration: 12351, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 12361, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 12371, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 12381, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 12391, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 12401, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 12411, Training Loss: 0.0074, Training Accuracy: 0.9922\n",
      "Iteration: 12421, Training Loss: 0.0021, Training Accuracy: 1.0000\n",
      "Iteration: 12431, Training Loss: 0.0036, Training Accuracy: 1.0000\n",
      "Iteration: 12441, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 12451, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 12461, Training Loss: 0.0016, Training Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 12471, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 12481, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 12491, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 12501, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 12511, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 12521, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 12531, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 12541, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 12551, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 12561, Training Loss: 0.0056, Training Accuracy: 1.0000\n",
      "Iteration: 12571, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 12581, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 12591, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 12601, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 12611, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 12621, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 12631, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 12641, Training Loss: 0.0025, Training Accuracy: 1.0000\n",
      "Iteration: 12651, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 12661, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 12671, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 12681, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 12691, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 12701, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 12711, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 12721, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 12731, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 12741, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 12751, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 12761, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 12771, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 12781, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 12791, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 12801, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 12811, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 12821, Training Loss: 0.0044, Training Accuracy: 1.0000\n",
      "Iteration: 12831, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 12841, Training Loss: 0.0025, Training Accuracy: 1.0000\n",
      "Iteration: 12851, Training Loss: 0.0111, Training Accuracy: 0.9922\n",
      "Iteration: 12861, Training Loss: 0.0052, Training Accuracy: 1.0000\n",
      "Iteration: 12871, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 12881, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 12891, Training Loss: 0.0043, Training Accuracy: 1.0000\n",
      "Iteration: 12901, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 12911, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 12921, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 12931, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 12941, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 12951, Training Loss: 0.0120, Training Accuracy: 0.9922\n",
      "Iteration: 12961, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 12971, Training Loss: 0.0058, Training Accuracy: 0.9922\n",
      "Iteration: 12981, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 12991, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 13001, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 13011, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 13021, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 13031, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 13041, Training Loss: 0.0039, Training Accuracy: 1.0000\n",
      "Iteration: 13051, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 13061, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 13071, Training Loss: 0.0019, Training Accuracy: 1.0000\n",
      "Iteration: 13081, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 13091, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 13101, Training Loss: 0.0068, Training Accuracy: 1.0000\n",
      "Iteration: 13111, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 13121, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 13131, Training Loss: 0.0124, Training Accuracy: 0.9922\n",
      "Iteration: 13141, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 13151, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 13161, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 13171, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 13181, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 13191, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 13201, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 13211, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 13221, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 13231, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 13241, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 13251, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 13261, Training Loss: 0.0040, Training Accuracy: 1.0000\n",
      "Iteration: 13271, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 13281, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 13291, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 13301, Training Loss: 0.0035, Training Accuracy: 1.0000\n",
      "Iteration: 13311, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 13321, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 13331, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 13341, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 13351, Training Loss: 0.0023, Training Accuracy: 1.0000\n",
      "Iteration: 13361, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 13371, Training Loss: 0.0023, Training Accuracy: 1.0000\n",
      "Iteration: 13381, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 13391, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 13401, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 13411, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 13421, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 13431, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 13441, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 13451, Training Loss: 0.0019, Training Accuracy: 1.0000\n",
      "Iteration: 13461, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 13471, Training Loss: 0.0015, Training Accuracy: 1.0000\n",
      "Iteration: 13481, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 13491, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 13501, Training Loss: 0.0017, Training Accuracy: 1.0000\n",
      "Iteration: 13511, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 13521, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 13531, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 13541, Training Loss: 0.0133, Training Accuracy: 0.9922\n",
      "Iteration: 13551, Training Loss: 0.0060, Training Accuracy: 0.9922\n",
      "Iteration: 13561, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 13571, Training Loss: 0.0027, Training Accuracy: 1.0000\n",
      "Iteration: 13581, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 13591, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 13601, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 13611, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 13621, Training Loss: 0.0081, Training Accuracy: 0.9922\n",
      "Iteration: 13631, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 13641, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 13651, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 13661, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 13671, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 13681, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 13691, Training Loss: 0.0011, Training Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 13701, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 13711, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 13721, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 13731, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 13741, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 13751, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 13761, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 13771, Training Loss: 0.0028, Training Accuracy: 1.0000\n",
      "Iteration: 13781, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 13791, Training Loss: 0.0016, Training Accuracy: 1.0000\n",
      "Iteration: 13801, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 13811, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 13821, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 13831, Training Loss: 0.0016, Training Accuracy: 1.0000\n",
      "Iteration: 13841, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 13851, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 13861, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 13871, Training Loss: 0.0108, Training Accuracy: 0.9922\n",
      "Iteration: 13881, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 13891, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 13901, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 13911, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 13921, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 13931, Training Loss: 0.0018, Training Accuracy: 1.0000\n",
      "Iteration: 13941, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 13951, Training Loss: 0.0015, Training Accuracy: 1.0000\n",
      "Iteration: 13961, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 13971, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 13981, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 13991, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 14001, Training Loss: 0.0025, Training Accuracy: 1.0000\n",
      "Iteration: 14011, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 14021, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 14031, Training Loss: 0.0030, Training Accuracy: 1.0000\n",
      "Iteration: 14041, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 14051, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 14061, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 14071, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 14081, Training Loss: 0.0165, Training Accuracy: 0.9922\n",
      "Iteration: 14091, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 14101, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 14111, Training Loss: 0.0024, Training Accuracy: 1.0000\n",
      "Iteration: 14121, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 14131, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 14141, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 14151, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 14161, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 14171, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 14181, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 14191, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 14201, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 14211, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 14221, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 14231, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 14241, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 14251, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 14261, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 14271, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 14281, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 14291, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 14301, Training Loss: 0.0079, Training Accuracy: 0.9922\n",
      "Iteration: 14311, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 14321, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 14331, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 14341, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 14351, Training Loss: 0.0027, Training Accuracy: 1.0000\n",
      "Iteration: 14361, Training Loss: 0.0040, Training Accuracy: 1.0000\n",
      "Iteration: 14371, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 14381, Training Loss: 0.0027, Training Accuracy: 1.0000\n",
      "Iteration: 14391, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 14401, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 14411, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 14421, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 14431, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 14441, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 14451, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 14461, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 14471, Training Loss: 0.0050, Training Accuracy: 1.0000\n",
      "Iteration: 14481, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 14491, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 14501, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 14511, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 14521, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 14531, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 14541, Training Loss: 0.0049, Training Accuracy: 1.0000\n",
      "Iteration: 14551, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 14561, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 14571, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 14581, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 14591, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 14601, Training Loss: 0.0066, Training Accuracy: 1.0000\n",
      "Iteration: 14611, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 14621, Training Loss: 0.0073, Training Accuracy: 1.0000\n",
      "Iteration: 14631, Training Loss: 0.0120, Training Accuracy: 0.9922\n",
      "Iteration: 14641, Training Loss: 0.0030, Training Accuracy: 1.0000\n",
      "Iteration: 14651, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 14661, Training Loss: 0.0022, Training Accuracy: 1.0000\n",
      "Iteration: 14671, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 14681, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 14691, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 14701, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 14711, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 14721, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 14731, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 14741, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 14751, Training Loss: 0.0193, Training Accuracy: 0.9922\n",
      "Iteration: 14761, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 14771, Training Loss: 0.0090, Training Accuracy: 0.9922\n",
      "Iteration: 14781, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 14791, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 14801, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 14811, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 14821, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 14831, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 14841, Training Loss: 0.0019, Training Accuracy: 1.0000\n",
      "Iteration: 14851, Training Loss: 0.0186, Training Accuracy: 0.9922\n",
      "Iteration: 14861, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 14871, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 14881, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 14891, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 14901, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 14911, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 14921, Training Loss: 0.0003, Training Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 14931, Training Loss: 0.0026, Training Accuracy: 1.0000\n",
      "Iteration: 14941, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 14951, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 14961, Training Loss: 0.0040, Training Accuracy: 1.0000\n",
      "Iteration: 14971, Training Loss: 0.0044, Training Accuracy: 1.0000\n",
      "Iteration: 14981, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 14991, Training Loss: 0.0018, Training Accuracy: 1.0000\n",
      "Iteration: 15001, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 15011, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 15021, Training Loss: 0.0021, Training Accuracy: 1.0000\n",
      "Iteration: 15031, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 15041, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 15051, Training Loss: 0.0056, Training Accuracy: 1.0000\n",
      "Iteration: 15061, Training Loss: 0.0037, Training Accuracy: 1.0000\n",
      "Iteration: 15071, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 15081, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 15091, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 15101, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 15111, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 15121, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 15131, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 15141, Training Loss: 0.0019, Training Accuracy: 1.0000\n",
      "Iteration: 15151, Training Loss: 0.0018, Training Accuracy: 1.0000\n",
      "Iteration: 15161, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 15171, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 15181, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 15191, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 15201, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 15211, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 15221, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 15231, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 15241, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 15251, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 15261, Training Loss: 0.0042, Training Accuracy: 1.0000\n",
      "Iteration: 15271, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 15281, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 15291, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 15301, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 15311, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 15321, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 15331, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 15341, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 15351, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 15361, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 15371, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 15381, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 15391, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 15401, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 15411, Training Loss: 0.0037, Training Accuracy: 1.0000\n",
      "Iteration: 15421, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 15431, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 15441, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 15451, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 15461, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 15471, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 15481, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 15491, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 15501, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 15511, Training Loss: 0.0034, Training Accuracy: 1.0000\n",
      "Iteration: 15521, Training Loss: 0.0088, Training Accuracy: 1.0000\n",
      "Iteration: 15531, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 15541, Training Loss: 0.0029, Training Accuracy: 1.0000\n",
      "Iteration: 15551, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 15561, Training Loss: 0.0015, Training Accuracy: 1.0000\n",
      "Iteration: 15571, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 15581, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 15591, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 15601, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 15611, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 15621, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 15631, Training Loss: 0.0037, Training Accuracy: 1.0000\n",
      "Iteration: 15641, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 15651, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 15661, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 15671, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 15681, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 15691, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 15701, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 15711, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 15721, Training Loss: 0.0034, Training Accuracy: 1.0000\n",
      "Iteration: 15731, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 15741, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 15751, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 15761, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 15771, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 15781, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 15791, Training Loss: 0.0036, Training Accuracy: 1.0000\n",
      "Iteration: 15801, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 15811, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 15821, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 15831, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 15841, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 15851, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 15861, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 15871, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 15881, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 15891, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 15901, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 15911, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 15921, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 15931, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 15941, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 15951, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 15961, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 15971, Training Loss: 0.0055, Training Accuracy: 1.0000\n",
      "Iteration: 15981, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 15991, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 16001, Training Loss: 0.0028, Training Accuracy: 1.0000\n",
      "Iteration: 16011, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 16021, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 16031, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 16041, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 16051, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 16061, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 16071, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 16081, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 16091, Training Loss: 0.0016, Training Accuracy: 1.0000\n",
      "Iteration: 16101, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 16111, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 16121, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 16131, Training Loss: 0.0203, Training Accuracy: 0.9922\n",
      "Iteration: 16141, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 16151, Training Loss: 0.0005, Training Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 16161, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 16171, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 16181, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 16191, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 16201, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 16211, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 16221, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 16231, Training Loss: 0.0113, Training Accuracy: 0.9922\n",
      "Iteration: 16241, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 16251, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 16261, Training Loss: 0.0019, Training Accuracy: 1.0000\n",
      "Iteration: 16271, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 16281, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 16291, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 16301, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 16311, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 16321, Training Loss: 0.0035, Training Accuracy: 1.0000\n",
      "Iteration: 16331, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 16341, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 16351, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 16361, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 16371, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 16381, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 16391, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 16401, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 16411, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 16421, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 16431, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 16441, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 16451, Training Loss: 0.0050, Training Accuracy: 1.0000\n",
      "Iteration: 16461, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 16471, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 16481, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 16491, Training Loss: 0.0078, Training Accuracy: 0.9922\n",
      "Iteration: 16501, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 16511, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 16521, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 16531, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 16541, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 16551, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 16561, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 16571, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 16581, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 16591, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 16601, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 16611, Training Loss: 0.0015, Training Accuracy: 1.0000\n",
      "Iteration: 16621, Training Loss: 0.0026, Training Accuracy: 1.0000\n",
      "Iteration: 16631, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 16641, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 16651, Training Loss: 0.0110, Training Accuracy: 0.9922\n",
      "Iteration: 16661, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 16671, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 16681, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 16691, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 16701, Training Loss: 0.0028, Training Accuracy: 1.0000\n",
      "Iteration: 16711, Training Loss: 0.0015, Training Accuracy: 1.0000\n",
      "Iteration: 16721, Training Loss: 0.0039, Training Accuracy: 1.0000\n",
      "Iteration: 16731, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 16741, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 16751, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 16761, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 16771, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 16781, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 16791, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 16801, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 16811, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 16821, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 16831, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 16841, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 16851, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 16861, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 16871, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 16881, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 16891, Training Loss: 0.0037, Training Accuracy: 1.0000\n",
      "Iteration: 16901, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 16911, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 16921, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 16931, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 16941, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 16951, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 16961, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 16971, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 16981, Training Loss: 0.0030, Training Accuracy: 1.0000\n",
      "Iteration: 16991, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 17001, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 17011, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 17021, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 17031, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 17041, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 17051, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 17061, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 17071, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 17081, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 17091, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17101, Training Loss: 0.0091, Training Accuracy: 0.9922\n",
      "Iteration: 17111, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 17121, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 17131, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 17141, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17151, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 17161, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 17171, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 17181, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 17191, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 17201, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 17211, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17221, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 17231, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 17241, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 17251, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 17261, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17271, Training Loss: 0.0038, Training Accuracy: 1.0000\n",
      "Iteration: 17281, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17291, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 17301, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 17311, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 17321, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 17331, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17341, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 17351, Training Loss: 0.0024, Training Accuracy: 1.0000\n",
      "Iteration: 17361, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 17371, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 17381, Training Loss: 0.0000, Training Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 17391, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 17401, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 17411, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 17421, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17431, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17441, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 17451, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 17461, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 17471, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17481, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 17491, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 17501, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 17511, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 17521, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17531, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 17541, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17551, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 17561, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 17571, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 17581, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 17591, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 17601, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 17611, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 17621, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17631, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 17641, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17651, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 17661, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 17671, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 17681, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17691, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 17701, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17711, Training Loss: 0.0027, Training Accuracy: 1.0000\n",
      "Iteration: 17721, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 17731, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 17741, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17751, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 17761, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 17771, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 17781, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 17791, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 17801, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 17811, Training Loss: 0.0097, Training Accuracy: 0.9922\n",
      "Iteration: 17821, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 17831, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17841, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17851, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 17861, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 17871, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 17881, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17891, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17901, Training Loss: 0.0015, Training Accuracy: 1.0000\n",
      "Iteration: 17911, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 17921, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 17931, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17941, Training Loss: 0.0313, Training Accuracy: 0.9922\n",
      "Iteration: 17951, Training Loss: 0.0044, Training Accuracy: 1.0000\n",
      "Iteration: 17961, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17971, Training Loss: 0.0016, Training Accuracy: 1.0000\n",
      "Iteration: 17981, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 17991, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18001, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 18011, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 18021, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18031, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18041, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18051, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18061, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 18071, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18081, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18091, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 18101, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 18111, Training Loss: 0.0025, Training Accuracy: 1.0000\n",
      "Iteration: 18121, Training Loss: 0.0011, Training Accuracy: 1.0000\n",
      "Iteration: 18131, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18141, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18151, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18161, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 18171, Training Loss: 0.0378, Training Accuracy: 0.9922\n",
      "Iteration: 18181, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 18191, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 18201, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 18211, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18221, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18231, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 18241, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 18251, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18261, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18271, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18281, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18291, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 18301, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 18311, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 18321, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 18331, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 18341, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 18351, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18361, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 18371, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18381, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18391, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 18401, Training Loss: 0.0013, Training Accuracy: 1.0000\n",
      "Iteration: 18411, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18421, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 18431, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18441, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18451, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 18461, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 18471, Training Loss: 0.0018, Training Accuracy: 1.0000\n",
      "Iteration: 18481, Training Loss: 0.0027, Training Accuracy: 1.0000\n",
      "Iteration: 18491, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18501, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18511, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18521, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 18531, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 18541, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18551, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 18561, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18571, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18581, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18591, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 18601, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18611, Training Loss: 0.0002, Training Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 18621, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18631, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18641, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 18651, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18661, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18671, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 18681, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18691, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 18701, Training Loss: 0.0102, Training Accuracy: 0.9922\n",
      "Iteration: 18711, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 18721, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 18731, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18741, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18751, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 18761, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18771, Training Loss: 0.0026, Training Accuracy: 1.0000\n",
      "Iteration: 18781, Training Loss: 0.0021, Training Accuracy: 1.0000\n",
      "Iteration: 18791, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18801, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18811, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18821, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18831, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18841, Training Loss: 0.0047, Training Accuracy: 1.0000\n",
      "Iteration: 18851, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18861, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18871, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 18881, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18891, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18901, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18911, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18921, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18931, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18941, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 18951, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18961, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 18971, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 18981, Training Loss: 0.0040, Training Accuracy: 1.0000\n",
      "Iteration: 18991, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19001, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19011, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 19021, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19031, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 19041, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 19051, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19061, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19071, Training Loss: 0.0026, Training Accuracy: 1.0000\n",
      "Iteration: 19081, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 19091, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19101, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 19111, Training Loss: 0.0052, Training Accuracy: 1.0000\n",
      "Iteration: 19121, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 19131, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 19141, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19151, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19161, Training Loss: 0.0017, Training Accuracy: 1.0000\n",
      "Iteration: 19171, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 19181, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 19191, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19201, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 19211, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 19221, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 19231, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19241, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 19251, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19261, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19271, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 19281, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 19291, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19301, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19311, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19321, Training Loss: 0.0018, Training Accuracy: 1.0000\n",
      "Iteration: 19331, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 19341, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 19351, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19361, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 19371, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 19381, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19391, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 19401, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19411, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19421, Training Loss: 0.0076, Training Accuracy: 1.0000\n",
      "Iteration: 19431, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 19441, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 19451, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 19461, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 19471, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19481, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 19491, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 19501, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 19511, Training Loss: 0.0012, Training Accuracy: 1.0000\n",
      "Iteration: 19521, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 19531, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 19541, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 19551, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 19561, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 19571, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19581, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 19591, Training Loss: 0.0023, Training Accuracy: 1.0000\n",
      "Iteration: 19601, Training Loss: 0.0020, Training Accuracy: 1.0000\n",
      "Iteration: 19611, Training Loss: 0.0028, Training Accuracy: 1.0000\n",
      "Iteration: 19621, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19631, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 19641, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 19651, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 19661, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19671, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 19681, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 19691, Training Loss: 0.0043, Training Accuracy: 1.0000\n",
      "Iteration: 19701, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 19711, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 19721, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19731, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 19741, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19751, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 19761, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 19771, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 19781, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19791, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19801, Training Loss: 0.0018, Training Accuracy: 1.0000\n",
      "Iteration: 19811, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19821, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19831, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 19841, Training Loss: 0.0001, Training Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 19851, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 19861, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 19871, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 19881, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 19891, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 19901, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 19911, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 19921, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 19931, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 19941, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 19951, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 19961, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 19971, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 19981, Training Loss: 0.0039, Training Accuracy: 1.0000\n",
      "Iteration: 19991, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 20001, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 20011, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 20021, Training Loss: 0.0020, Training Accuracy: 1.0000\n",
      "Iteration: 20031, Training Loss: 0.0034, Training Accuracy: 1.0000\n",
      "Iteration: 20041, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 20051, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 20061, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20071, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 20081, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 20091, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 20101, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20111, Training Loss: 0.0009, Training Accuracy: 1.0000\n",
      "Iteration: 20121, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 20131, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 20141, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 20151, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20161, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 20171, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 20181, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 20191, Training Loss: 0.0247, Training Accuracy: 0.9922\n",
      "Iteration: 20201, Training Loss: 0.0019, Training Accuracy: 1.0000\n",
      "Iteration: 20211, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20221, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 20231, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 20241, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20251, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20261, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 20271, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20281, Training Loss: 0.0014, Training Accuracy: 1.0000\n",
      "Iteration: 20291, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 20301, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20311, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20321, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 20331, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 20341, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20351, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 20361, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 20371, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20381, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 20391, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 20401, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 20411, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 20421, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 20431, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20441, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 20451, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 20461, Training Loss: 0.0010, Training Accuracy: 1.0000\n",
      "Iteration: 20471, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20481, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20491, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 20501, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20511, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 20521, Training Loss: 0.0008, Training Accuracy: 1.0000\n",
      "Iteration: 20531, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 20541, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20551, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 20561, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20571, Training Loss: 0.0060, Training Accuracy: 0.9922\n",
      "Iteration: 20581, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 20591, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 20601, Training Loss: 0.0016, Training Accuracy: 1.0000\n",
      "Iteration: 20611, Training Loss: 0.0006, Training Accuracy: 1.0000\n",
      "Iteration: 20621, Training Loss: 0.0022, Training Accuracy: 1.0000\n",
      "Iteration: 20631, Training Loss: 0.0043, Training Accuracy: 1.0000\n",
      "Iteration: 20641, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20651, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 20661, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20671, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 20681, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20691, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20701, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 20711, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 20721, Training Loss: 0.0019, Training Accuracy: 1.0000\n",
      "Iteration: 20731, Training Loss: 0.0019, Training Accuracy: 1.0000\n",
      "Iteration: 20741, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 20751, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20761, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 20771, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 20781, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20791, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 20801, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20811, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 20821, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20831, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 20841, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 20851, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 20861, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 20871, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 20881, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20891, Training Loss: 0.0078, Training Accuracy: 0.9922\n",
      "Iteration: 20901, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 20911, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 20921, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 20931, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20941, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20951, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 20961, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20971, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 20981, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 20991, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 21001, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 21011, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 21021, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 21031, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 21041, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 21051, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 21061, Training Loss: 0.0027, Training Accuracy: 1.0000\n",
      "Iteration: 21071, Training Loss: 0.0000, Training Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 21081, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 21091, Training Loss: 0.0040, Training Accuracy: 1.0000\n",
      "Iteration: 21101, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 21111, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 21121, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 21131, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 21141, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 21151, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 21161, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 21171, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 21181, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 21191, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 21201, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 21211, Training Loss: 0.0033, Training Accuracy: 1.0000\n",
      "Iteration: 21221, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 21231, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 21241, Training Loss: 0.0015, Training Accuracy: 1.0000\n",
      "Iteration: 21251, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 21261, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 21271, Training Loss: 0.0004, Training Accuracy: 1.0000\n",
      "Iteration: 21281, Training Loss: 0.0183, Training Accuracy: 0.9922\n",
      "Iteration: 21291, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 21301, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 21311, Training Loss: 0.0002, Training Accuracy: 1.0000\n",
      "Iteration: 21321, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 21331, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 21341, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 21351, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 21361, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 21371, Training Loss: 0.0044, Training Accuracy: 1.0000\n",
      "Iteration: 21381, Training Loss: 0.0007, Training Accuracy: 1.0000\n",
      "Iteration: 21391, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 21401, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 21411, Training Loss: 0.0005, Training Accuracy: 1.0000\n",
      "Iteration: 21421, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 21431, Training Loss: 0.0000, Training Accuracy: 1.0000\n",
      "Iteration: 21441, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 21451, Training Loss: 0.0108, Training Accuracy: 0.9922\n",
      "Iteration: 21461, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iteration: 21471, Training Loss: 0.0003, Training Accuracy: 1.0000\n",
      "Iteration: 21481, Training Loss: 0.0001, Training Accuracy: 1.0000\n",
      "Iterations: 21485, Test Loss: 0.0278, Test Accuracy: 0.9930\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step=1\n",
    "    while step <= num_of_iters:       \n",
    "        batch_x, batch_y = mnist.train.next_batch(batchsize)  \n",
    "        sess.run(train_min, feed_dict={X:batch_x, Y:batch_y})        \n",
    "        losscalc, accuracycalc, merged_summary = sess.run([loss, accuracy,merged_summary_op], feed_dict={X:batch_x, Y:batch_y})\n",
    "        if (step%10==1):\n",
    "            print(\"Iteration: %d, Training Loss: %0.4f, Training Accuracy: %0.4f\"%(step, losscalc, accuracycalc))\n",
    "        writer.add_summary(merged_summary, step)\n",
    "        step += 1\n",
    "        \n",
    "    test_x, test_y = mnist.test.next_batch(10000)\n",
    "    losscalc, accuracycalc = sess.run([loss, accuracy], feed_dict={X:test_x, Y:test_y})\n",
    "    print(\"Iterations: %d, Test Loss: %0.4f, Test Accuracy: %0.4f\"%(step, losscalc, accuracycalc))\n",
    "\n",
    "writer.close()               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
